---
title: " "
format: html
---

# Análise de Variância (ANOVA)

## ANOVA em DIC

A ANOVA é uma técnica estatística normalmente utilizada para comparar as médias de três ou mais grupos distintos e determinar se existem diferenças estatisticamente significativas entre essas médias. A ANOVA é particularmente útil quando se deseja testar a hipótese de que várias populações têm a mesma média.

Aqui veremos como realizar a ANOVA para dados provenientes de experimentos conduzidos em DIC (Delineamento Inteiramente Casualizado) que é uma técnica estatística frequentemente utilizada em experimentos para comparar tratamentos onde a distribuição dos tratamentos às unidades experimentais é feita inteiramente ao acaso. Como não faz restrições na casualização, o uso do DIC pressupõe que as unidades experimentais estão sob condições homogêneas.

Pacotes utilizados:

```{r warning=FALSE, message=FALSE}
library(gsheet)
library(tidyverse)
library(ggthemes)

```

Importando os dados e vizualizando

```{r warning=FALSE, message=FALSE}
micelial <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827")

#Vizualizar
micelial |> 
  ggplot(aes(especie, tcm))+
  geom_boxplot(fill = "gray")+
  geom_jitter(width = 0.1, size = 2)+
  theme_few()

```

Realizando a ANOVA

A anova pode ser raalizada através da função `aov()` ou `lm()` do R básico. A função `lm()`, além de realizar\< pode ser utilizada para ajustar modelos lineares ao conjunto de dados, portanto é mais completa que a `aov()`.

```{r}
anova_micelial <- aov(tcm ~ especie, data = micelial)
 
anova_micelial

```

Resumo dos resultados através da função `summary()`:

```{r}
summary(anova_micelial)

```

Obtendo o quadro da ANOVA com a função `anova()`:

```{r}
anova(anova_micelial)

```

ANOVA feita com a função `lm()`:

```{r}
anova_micelial2 <- lm(tcm ~ especie, data = micelial)

anova_micelial2

```

```{r}
summary(anova_micelial2)

```

```{r}
anova(anova_micelial2)

```

## Pressuposições da ANOVA e Testes de Médias

A ANOVA possui várias pressuposições fundamentais que devem ser atendidas para que os resultados sejam válidos. Aqui iremos demonstrar diferentes meios de verificar estas presusuposições.

### Normalidade dos Resíduos

Os resíduos (diferenças entre os valores observados e as médias dos grupos) devem seguir uma distribuição normal.

Veja diferentes maneiras de como testar a normalidade dos resíduos do conjunto de dados submetido a ANOVA

Opção 1: Teste de Shapiro

```{r}
shapiro.test(anova_micelial2$residuals) # H0 é de que os resíduos apresentam distribuição normal

```

Opção 2: Gráfico de histograma para os resíduos

```{r}
hist(anova_micelial2$residuals)

```

Opção 3: Utilizando o pacote **perfomance**

```{r warning=FALSE, message=FALSE}
library(performance)

check_normality(anova_micelial2)

```

### Homogeneidade das Variâncias (Homoscedasticidade)

As variâncias dos resíduos devem ser aproximadamente iguais entre os grupos. A violação dessa pressuposição pode levar a resultados incorretos, pois a ANOVA assume que a variabilidade dentro de cada grupo é similar.

Veja maneiras diferentes de verificar esta premissa

Opção 1: Teste de Bartlett

```{r}
bartlett.test(tcm ~ especie, data = micelial) # H0 é que a variâncias são homogêneas

```

Opção 2: Utilizando o pacote **perfomance**

```{r}
check_heteroscedasticity(anova_micelial2)

```

### Otimizando os teste de pressuposições para ANVOA

Você pode utilizar o pacote **performance** para checar mais pressuposições com a função `check_model()`:

```{r}
plot_presup <- check_model(anova_micelial2)

plot_presup

```

O pacote **DHARMA** também pode ser utilizado para checar normalidade e homoscedasticidade

```{r warning=FALSE, message=FALSE}
library(DHARMa)

plot(simulateResiduals(anova_micelial2))

```

## Testes de Comparações Múltiplas

Quando a ANOVA é significativa, isso indica que há pelo menos uma diferença significativa entre as médias dos grupos comparados. No entanto, a ANOVA não especifica quais grupos diferem entre si. Para identificar essas diferenças específicas, é necessário realizar testes de comparações múltiplas.

Um teste amplamente utilizado é o Teste de Tukey, utilizado para comparações múltiplas entre todas as possíveis pares de médias.

Veja como realizá-lo:

```{r warning=FALSE, message=FALSE}
#Demonstrando os agrupamentos de médias
library(emmeans)
library(multcomp)

medias_lm <- emmeans(anova_micelial2, ~ especie) # Obtendo as médias do conjunto de dados

medias_lm

```

A função `cld()` do pacote **multcomp** separa os grupos de média via Teste Tukey

```{r}
cld(medias_lm, Letters = letters)

```

## Transformação de dados e alternativas não-paramétricas da ANOVA

E se as pressuposições não forem atendidas?

Neste caso podemos aplicar diferentes transformações nos dados (raiz quadrada, logarítmica ou boxcox), para tentar atender às premissas de normalidade e homogeneidade das variâncias.

Veremos as transformações para um novo conjunto de dados onde as premissas para a ANOVA não são atendidas:

```{r}
Inseticida <- InsectSprays

```

### Tranformação por raiz quadrada e logarítmica

Transformando os dados via raiz quadrada, realizando a ANOVA e testando as pressuposições, temos os seguintes chunks:

```{r}
Inseticida <- Inseticida |> 
  mutate(count2 = sqrt(count))

# Vizualizando após a transformação
Inseticida |> 
  ggplot(aes(spray, count2, fill= spray))+
  geom_boxplot()+
  geom_jitter(width = 0.05, size = 2)+
  theme_few()+
  scale_fill_few()+
  theme(legend.title = element_blank(), legend.position = "none")

```

```{r}
m2 <- lm (count2 ~ spray, data = Inseticida)

anova(m2)

```

```{r}
plot(simulateResiduals(m2))

```

A transformação logarítima pode ser feita substituindo a função `sqrt()` por `log()`.

### Transformação BoxCox

A transformação Box-Cox é definida por uma família de transformações parametrizadas por lambda (λ)

Processo de aplicação consiste em estimar lambda (λ), calculando a transformação para uma série de valores possíveis de λ (geralmente de -2 a 2, por exemplo) e escolhendo aquela que maximiza a normalidade dos dados transformados. Posteriormente, aplicar a transformação aos dados originais y\^(λ), onde y é a variável de interesse.

O pacote **MASS** possui as funções úteis para realizar essa transformação. Veja:

```{r}
library(MASS)

b <- boxcox(lm(Inseticida$count+0.1 ~ 1))
lambda <- b$x[which.max(b$y)]
lambda = 0.5

Inseticida$count3 <-(Inseticida$count ^ lambda - 1) / lambda

```

```{r}
hist(Inseticida$count3)

```

```{r}
m3 <- lm (count3 ~ spray, data = Inseticida)

plot(simulateResiduals(m3))

```

### Teste de Kruskal-Walis

Se isso não for eficaz, podem ser utilizados testes não paramétricos, como o teste de Kruskal-Wallis, que não assume normalidade dos dados.

```{r}
library(agricolae)
kruskal.test(count ~ spray, data = Inseticida)

m3 <- kruskal(Inseticida$count,
        Inseticida$spray,
        group = TRUE)

m3

```

### Modelos Lineares Não Generelaziados

Os modelos lineares não generalizados permitem modelar relações entre variáveis dependentes e independentes, mesmo quando a distribuição dos dados não é normal ou quando a variância não é constante.

Você pode utilizar a função `glm()` do R básico, identificando a distribuição que mais adequa aos seus dados no argumento `family =`.

Aqui assumimos a distribuição de poisson.

```{r}
m4 <- glm(count ~ spray,
          family = poisson,
          data = Inseticida)

m4

```

```{r}
anova(m4)

```

```{r}
plot(simulateResiduals(m4))

```

```{r}
medias4 <- emmeans(m4, ~ spray, type = "response")

cld(medias4, Letters = letters)

```
