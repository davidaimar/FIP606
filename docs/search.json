[
  {
    "objectID": "R_codes/Introdução.html",
    "href": "R_codes/Introdução.html",
    "title": "Conhecendo o R",
    "section": "",
    "text": "O R é um software amplamente utilizado por estatísticos, analistas de dados, cientistas de dados e pesquisadores para realizar análises estatística, visualização gráfica, modelagem estatística, computação científica e que também pode ser utilizado como uma linguagem de programação. Esta ferramenta está sob livre acesso mediante os termos da Licença Pública Geral GNU da Free Software Foundation."
  },
  {
    "objectID": "R_codes/Introdução.html#a-interface-do-rstudio",
    "href": "R_codes/Introdução.html#a-interface-do-rstudio",
    "title": "Conhecendo o R",
    "section": "A interface do RStudio",
    "text": "A interface do RStudio\nA interface do RStudio oferece recursos como:\nEditor de script: Um editor de texto avançado para escrever e editar scripts em R.\nConsole: Onde os comandos em R podem ser executados interativamente.\nAmbiente de trabalho: Uma visualização das variáveis, dados e objetos atualmente carregados na sessão de R.\nPainel de arquivos: Para navegação e gestão de arquivos do projeto.\nVisualização de gráficos: Uma área dedicada para exibir gráficos gerados pelo código em R.\nFerramentas de depuração: Para ajudar a encontrar e corrigir erros no código.\nO RStudio facilita o trabalho com R, tornando-o mais eficiente e acessível, especialmente para iniciantes na linguagem."
  },
  {
    "objectID": "R_codes/Aula_8.html",
    "href": "R_codes/Aula_8.html",
    "title": "FIP606",
    "section": "",
    "text": "Experimentos fatoriais são aqueles em que se estudam simultaneamente dois ou mais fatores, cada um deles com dois ou mais níveis.\nO fatorial é um tipo de esquema, ou seja, uma das maneiras de organizar os tratamentos e não um tipo de delineamento, que representa a maneira pela qual os tratamentos são distribuídos às unidades experimentais.\nAqui você aprenderá a realizar uma ANOVA fatorial no R.\nPacotes necessários\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(ggthemes)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\n\nRealizando a Importação, Vizualização Gráfica, Anova Fatorial, Checagem de Pressuposições e Tukey\n\nfungicida &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\nfungicida$dose &lt;- as.factor(fungicida$dose)\n\nfungicida |&gt; \n  ggplot(aes(treat,severity, color = dose))+\n  geom_jitter(width = 0.2, size = 2.5)+\n  theme_few()+\n  scale_fill_few()+\n  theme(legend.title = element_blank(), legend.position = \"none\")\n\n\n\n\n\nmf &lt;- lm(severity ~ treat*dose, data = fungicida)\n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplot(simulateResiduals(mf))\n\n\n\n\nO agrupamento de médias em experimentos fatoriais deve ser feito para cada fator em relação ao outro\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\n\ncld(mf_medias, Letters = letters)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  a    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   b   \n\ndose = 2:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  a    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nmf_medias_linha &lt;- emmeans(mf, ~ dose | treat)\n\ncld(mf_medias_linha,Letters = letters) \n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n 2    0.0501 0.0273 16 -0.00781   0.1080  a    \n 0.5  0.2921 0.0273 16  0.23420   0.3500   b   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n 2    0.0202 0.0273 16 -0.03768   0.0781  a    \n 0.5  0.0210 0.0273 16 -0.03690   0.0789  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_8.html#anova-fatorial",
    "href": "R_codes/Aula_8.html#anova-fatorial",
    "title": "FIP606",
    "section": "",
    "text": "Experimentos fatoriais são aqueles em que se estudam simultaneamente dois ou mais fatores, cada um deles com dois ou mais níveis.\nO fatorial é um tipo de esquema, ou seja, uma das maneiras de organizar os tratamentos e não um tipo de delineamento, que representa a maneira pela qual os tratamentos são distribuídos às unidades experimentais.\nAqui você aprenderá a realizar uma ANOVA fatorial no R.\nPacotes necessários\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(ggthemes)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\n\nRealizando a Importação, Vizualização Gráfica, Anova Fatorial, Checagem de Pressuposições e Tukey\n\nfungicida &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\nfungicida$dose &lt;- as.factor(fungicida$dose)\n\nfungicida |&gt; \n  ggplot(aes(treat,severity, color = dose))+\n  geom_jitter(width = 0.2, size = 2.5)+\n  theme_few()+\n  scale_fill_few()+\n  theme(legend.title = element_blank(), legend.position = \"none\")\n\n\n\n\n\nmf &lt;- lm(severity ~ treat*dose, data = fungicida)\n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplot(simulateResiduals(mf))\n\n\n\n\nO agrupamento de médias em experimentos fatoriais deve ser feito para cada fator em relação ao outro\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\n\ncld(mf_medias, Letters = letters)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  a    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   b   \n\ndose = 2:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  a    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nmf_medias_linha &lt;- emmeans(mf, ~ dose | treat)\n\ncld(mf_medias_linha,Letters = letters) \n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n 2    0.0501 0.0273 16 -0.00781   0.1080  a    \n 0.5  0.2921 0.0273 16  0.23420   0.3500   b   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n 2    0.0202 0.0273 16 -0.03768   0.0781  a    \n 0.5  0.0210 0.0273 16 -0.03690   0.0789  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_8.html#anova-em-experimentos-com-parcelas-subdivididas",
    "href": "R_codes/Aula_8.html#anova-em-experimentos-com-parcelas-subdivididas",
    "title": "FIP606",
    "section": "ANOVA em Experimentos com Parcelas Subdivididas",
    "text": "ANOVA em Experimentos com Parcelas Subdivididas\nTal como no caso de fatorial, o termo parcelas subdivididas se refere a um esquema do experimento, ou seja, a maneira pela qual os tratamentos são organizados. Havendo dois fatores, eles são designados como fator primário e secundário.\nNeste caso, as parcelas que recebem os níveis do fator primário são divididas em subparcelas que receberão os níveis do fator secundário.\nA ANOVA para esta condição será explorada a seguir\nImportando o conjunto de dados\n\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\nVizualização gráfica\n\nmilho |&gt; \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.01, color = \"black\")+\n  facet_wrap(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', size = 0.5, alpha = 0.5)+\n  theme_few()+\n    labs(x = 'Method',\n       y = 'Index')\n\n\n\n\n\nModelo para Anova em parcelas subdivididas\nUtilizamos os Modelos de Efeitos Mistos através da função lmer() do pacote lme4 e sumarizamos o resultado através da função Anova() do pacore car.\n\nlibrary(lme4)\nlibrary(car)\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix &lt;- lmer(index ~ hybrid*method + block + (1|block/hybrid), data = milho) # Modelos Lineares de Efeitos Mistos\n\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTestando as premissas\n\nlibrary(performance)\n\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\n\n\ncheck_heteroscedasticity(mix)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\n\nTransformando os dados\nHomoscedasticidade não atendida, portanto procederemos com a transformação dos dados via raiz quadrada\n\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), data = milho)\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0783  3   0.994305   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\n\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.970).\n\n\nPresseguindo com o teste de médias\n\nmedias_milho &lt;- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho2 &lt;- emmeans(mix2,\n                        ~ method | hybrid,\n                        type = \"response\")\n\nVizualizando o resultado\n\ncld(medias_milho, Letters = letters)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.3 5155     4.50     44.7  a    \n 30K64        20.3 10.5 5155     4.93     46.1  a    \n 30F53 YH     24.5 11.5 5155     7.11     52.3  ab   \n 30F53 HX     25.0 11.6 5155     7.35     53.0  ab   \n 30S31YH      31.7 13.1 5155    11.20     62.6  ab   \n 30S31H       37.1 14.2 5155    14.52     70.2   b   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.2 5155     4.35     44.3  a    \n 30K64        21.3 10.8 5155     5.44     47.6  a    \n 30F53 HX     24.4 11.5 5155     7.07     52.2  a    \n 30F53 YH     26.0 11.9 5155     7.95     54.6  a    \n 30S31H       26.3 12.0 5155     8.11     55.0  a    \n 30S31YH      26.4 12.0 5155     8.16     55.1  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 11.5 5155     7.07     52.2  a    \n pin        25.0 11.6 5155     7.35     53.0  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 11.5 5155     7.11     52.3  a    \n silk       26.0 11.9 5155     7.95     54.6  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.5 5155     4.93     46.1  a    \n silk       21.3 10.8 5155     5.44     47.6  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.0 5155     8.11     55.0  a    \n pin        37.1 14.2 5155    14.52     70.2   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.0 5155     8.16     55.1  a    \n pin        31.7 13.1 5155    11.20     62.6  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.2 5155     4.35     44.3  a    \n pin        19.4 10.3 5155     4.50     44.7  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nSegunda variável\nRepetindo a análise para uma outra variável, já incluindo a tranformação por raiz quadrada\n\nmix3&lt;- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), data = milho)\n\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nChecando as pressuposições\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\n\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\nTeste de médias\n\nmedias_milho_prod &lt;- emmeans(mix3,\n                        ~ hybrid | method,\n                        type = \"response\")\n\nmedias_milho_prod2 &lt;- emmeans(mix3,\n                        ~ method | hybrid,\n                        type = \"response\")\n\n\ncld(medias_milho_prod, Letters = letters)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  a    \n 30S31H       8081 743 26.1     6626     9681  ab   \n 30F53 YH     9314 798 26.1     7746    11027  abc  \n 30F53 HX    11130 872 26.1     9410    12995   bc  \n 30K64       11666 893 26.1     9903    13574    c  \n BG7049H     11914 903 26.1    10131    13841    c  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  a    \n 30F53 YH     9079 788 26.1     7532    10770  a    \n 30S31H       9135 790 26.1     7583    10832  a    \n 30F53 HX     9932 824 26.1     8311    11698  ab   \n 30K64       10331 840 26.1     8676    12131  ab   \n BG7049H     12822 936 26.1    10970    14818   b   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\ncld(medias_milho_prod2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  a    \n pin       11130 872 26.1     9410    12995   b   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  a    \n pin        9314 798 26.1     7746    11027  a    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  a    \n pin       11666 893 26.1     9903    13574   b   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  a    \n silk       9135 790 26.1     7583    10832   b   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  a    \n silk       8257 751 26.1     6785     9873  a    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  a    \n silk      12822 936 26.1    10970    14818  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_7.html",
    "href": "R_codes/Aula_7.html",
    "title": "FIP606",
    "section": "",
    "text": "Experimentos em DBC (Delineamento em Blocos Casualizados), são um tipo de design experimental utilizado para controlar variações provenientes de um ambiente exeperimental não homogêneo (não aleatórias) entre unidades experimentais.\nPodemos utilizar a função aov() ou lm() para realizar a ANOVA. A fórmula resposta ~ tratamento + Error(bloco) especifica que a variável resposta é explicada pelo efeito do tratamento, considerando o bloco como um fator de bloqueio (variável de erro).\nPacotes utilizados\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(ggthemes)\n\nImportando os dados\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT), BLOCO = as.factor(BLOCO))\n\nVizualização gráfica paras as variáveis\n\nlibrary(patchwork)\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.1, color = 'gray')+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', alpha = 0.5)+\n  theme_few()\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.1, color = 'gray')+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', alpha = 0.5)+\n  theme_few()\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1, color = 'gray')+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', alpha = 0.5)+\n  theme_few()\n\ndfc + fer + prod\n\n\n\n\nRealizando a ANOVA\n\naov_dfc &lt;- lm (DFC ~ TRAT + BLOCO, data = soja)\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVale lembrar que para prosseguir com a ANOVA em DBC as mesmas pressuposições para ANOVA em DIC devem ser atendidas. Os testes são feitos como foi demonstrado para ANOVA em DIC.\nObservando os grupos de médias\n\nlibrary(multcomp)\nlibrary(emmeans)\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\n\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\nTeste Tukey\n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nAgrupamento\n\ncld(medias_dfc, Letters = letters)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  a    \n 7      4.08 0.322 21     3.41     4.74  a    \n 5      4.20 0.322 21     3.53     4.87  a    \n 8      4.58 0.322 21     3.91     5.24  ab   \n 4      4.75 0.322 21     4.08     5.42  ab   \n 3      6.05 0.322 21     5.38     6.72   bc  \n 2      6.42 0.322 21     5.76     7.09    c  \n 1     10.88 0.322 21    10.21    11.54     d \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nQuando se tem mais de uma variável resposta no conjunto de dados a anova deve ser feita para cada uma."
  },
  {
    "objectID": "R_codes/Aula_7.html#anova-em-dbc",
    "href": "R_codes/Aula_7.html#anova-em-dbc",
    "title": "FIP606",
    "section": "",
    "text": "Experimentos em DBC (Delineamento em Blocos Casualizados), são um tipo de design experimental utilizado para controlar variações provenientes de um ambiente exeperimental não homogêneo (não aleatórias) entre unidades experimentais.\nPodemos utilizar a função aov() ou lm() para realizar a ANOVA. A fórmula resposta ~ tratamento + Error(bloco) especifica que a variável resposta é explicada pelo efeito do tratamento, considerando o bloco como um fator de bloqueio (variável de erro).\nPacotes utilizados\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(ggthemes)\n\nImportando os dados\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT), BLOCO = as.factor(BLOCO))\n\nVizualização gráfica paras as variáveis\n\nlibrary(patchwork)\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.1, color = 'gray')+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', alpha = 0.5)+\n  theme_few()\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.1, color = 'gray')+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', alpha = 0.5)+\n  theme_few()\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1, color = 'gray')+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', alpha = 0.5)+\n  theme_few()\n\ndfc + fer + prod\n\n\n\n\nRealizando a ANOVA\n\naov_dfc &lt;- lm (DFC ~ TRAT + BLOCO, data = soja)\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVale lembrar que para prosseguir com a ANOVA em DBC as mesmas pressuposições para ANOVA em DIC devem ser atendidas. Os testes são feitos como foi demonstrado para ANOVA em DIC.\nObservando os grupos de médias\n\nlibrary(multcomp)\nlibrary(emmeans)\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\n\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\nTeste Tukey\n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nAgrupamento\n\ncld(medias_dfc, Letters = letters)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  a    \n 7      4.08 0.322 21     3.41     4.74  a    \n 5      4.20 0.322 21     3.53     4.87  a    \n 8      4.58 0.322 21     3.91     5.24  ab   \n 4      4.75 0.322 21     4.08     5.42  ab   \n 3      6.05 0.322 21     5.38     6.72   bc  \n 2      6.42 0.322 21     5.76     7.09    c  \n 1     10.88 0.322 21    10.21    11.54     d \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nQuando se tem mais de uma variável resposta no conjunto de dados a anova deve ser feita para cada uma."
  },
  {
    "objectID": "R_codes/Aula_7.html#adicionando-as-letras-do-teste-tukey-em-gráficos",
    "href": "R_codes/Aula_7.html#adicionando-as-letras-do-teste-tukey-em-gráficos",
    "title": "FIP606",
    "section": "Adicionando as letras do Teste Tukey em Gráficos",
    "text": "Adicionando as letras do Teste Tukey em Gráficos\nOs resultados da análise de variância junto com o teste tukey podem ser ilustrados em gráficos.\nVeja a demonstração para a variável produtividade\n\naov_prod &lt;- lm (PROD ~ TRAT + BLOCO, data = soja)\n\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\n\ncld(medias_prod, Letters = letters)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  a    \n 2      4935 201 21     4516     5354  ab   \n 8      5078 201 21     4659     5497  ab   \n 3      5110 201 21     4691     5529  ab   \n 5      5122 201 21     4703     5541  ab   \n 7      5128 201 21     4709     5546  ab   \n 4      5140 201 21     4721     5559  ab   \n 6      5256 201 21     4837     5675   b   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nProduzindo o gráfico e adicionando as letras correspondentes aos grupos de médias:\n\ndf_prod &lt;- data.frame(medias_prod)\ndf_prod|&gt;\n  ggplot(aes(TRAT,emmean))+\n  geom_point()+\n  ylim(2000, 6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL,\n                    width = 0.1))+\n  theme_few()+\n  annotate(geom = \"text\", x = 1.2, y = 4250,\n           label = \"a\")+\n    annotate(geom = \"text\", x = 2.3, y = 4900,\n           label = \"ab\")+\n    annotate(geom = \"text\", x = 3.3, y = 5150,\n           label = \"ab\")+\n  annotate(geom = \"text\", x = 4.3, y = 5155,\n           label = \"ab\")+\n    annotate(geom = \"text\", x = 5.3, y = 5200,\n           label = \"ab\")+\n    annotate(geom = \"text\", x = 6.3, y = 5275,\n           label = \"ab\")+\n    annotate(geom = \"text\", x = 7.3, y = 5150,\n           label = \"ab\")+\n    annotate(geom = \"text\", x = 8.2, y = 5140,\n           label = \"b\")\n\n\n\n\nVeja também como sumarizar os resultados em uma tabela\n\ndf_prod &lt;- cld(medias_prod, Letters = LETTERS)\ndf_prod &lt;- as.data.frame(df_prod)\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\n\nwrite_xlsx(df_prod, \"df.xlsx\")"
  },
  {
    "objectID": "R_codes/Aula_7.html#área-abaixo-da-curva-de-progresso-da-doença-aacpd",
    "href": "R_codes/Aula_7.html#área-abaixo-da-curva-de-progresso-da-doença-aacpd",
    "title": "FIP606",
    "section": "Área Abaixo da Curva de Progresso da Doença (AACPD)",
    "text": "Área Abaixo da Curva de Progresso da Doença (AACPD)\nA AACPD é uma medida quantitativa utilizada em estudos agrícolas e de saúde para avaliar a evolução temporal de uma doença ou de outro fenômeno que varia ao longo do tempo. Essa métrica é especialmente útil em experimentos onde se deseja comparar diferentes tratamentos ou condições em relação à severidade ou incidência de uma doença ao longo de um período de tempo.\nVamos analisar um conjunto de dados que lida com valores de severidade ao longo do tempo\nImportação e vizualização dos dados\n\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\ncurve |&gt; \n  ggplot(aes(day, severity))+\n  geom_point()+\n  facet_wrap(~Irrigation)\n\n\n\ncurve |&gt; \n  group_by(day, Irrigation) |&gt; \n  summarise(mean_sev = mean(severity)) |&gt;\n  ggplot(aes(day, mean_sev, color = Irrigation))+\n  geom_point( color = \"black\")+\n  geom_line()+\n  theme_few()+\n  labs(x = \"Days\", y = \"Severity (%)\")\n\n`summarise()` has grouped output by 'day'. You can override using the `.groups`\nargument.\n\n\n\n\n\nObtenção da AACPD, através da função AUDPC() do pacote epifitter.\n\nlibrary(epifitter)\ncurve2 &lt;- curve |&gt; \n  group_by(Irrigation, rep) |&gt; \n  summarise(aacpd = AUDPC(day, severity))\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\n\nRealizando a ANOVA para AACPD\n\nm_curve &lt;- lm(aacpd ~ Irrigation + factor(rep),\n              data = curve2)\n\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nChecando as premissas\n\nlibrary(performance)\n\ncheck_normality(m_curve)\n\nOK: residuals appear as normally distributed (p = 0.380).\n\n\n\ncheck_heteroscedasticity(m_curve)\n\nOK: Error variance appears to be homoscedastic (p = 0.704).\n\n\nTeste Tukey\n\nlibrary(emmeans)\nlibrary(multcomp)\n\nmed_curve &lt;- emmeans(m_curve, ~ Irrigation)\n\ncld(med_curve, Letters = letters)\n\n Irrigation emmean     SE df lower.CL upper.CL .group\n Drip         13.4 0.0861  2     13.0     13.8  a    \n Furrow       13.8 0.0861  2     13.4     14.2  a    \n\nResults are averaged over the levels of: rep \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_7.html#coenficiente-de-variação-cv",
    "href": "R_codes/Aula_7.html#coenficiente-de-variação-cv",
    "title": "FIP606",
    "section": "Coenficiente de Variação (CV)",
    "text": "Coenficiente de Variação (CV)\nO CV é uma medida estatística que expressa a variabilidade relativa de uma amostra ou de um conjunto de dados em relação à sua média. Na ANOVA, o CV pode ser útil para comparar a dispersão dos dados entre diferentes tratamentos.\nO CV é calculado pelo desvio padrão amostral divido pela média amostral e mulriplicado por 100.\nÉ possivel obter o CV através da função cv.model() do pacote agricolae.\n\nlibrary(agricolae)\n\ncv.model(m_curve) # 'm_curve' é o objeto com a saída da última ANOVA realizada\n\n[1] 1.097572"
  },
  {
    "objectID": "R_codes/Aula_6.1.html",
    "href": "R_codes/Aula_6.1.html",
    "title": "Análise de Variância (ANOVA)",
    "section": "",
    "text": "A ANOVA é uma técnica estatística normalmente utilizada para comparar as médias de três ou mais grupos distintos e determinar se existem diferenças estatisticamente significativas entre essas médias. A ANOVA é particularmente útil quando se deseja testar a hipótese de que várias populações têm a mesma média.\nAqui veremos como realizar a ANOVA para dados provenientes de experimentos conduzidos em DIC (Delineamento Inteiramente Casualizado) que é uma técnica estatística frequentemente utilizada em experimentos para comparar tratamentos onde a distribuição dos tratamentos às unidades experimentais é feita inteiramente ao acaso. Como não faz restrições na casualização, o uso do DIC pressupõe que as unidades experimentais estão sob condições homogêneas.\nPacotes utilizados:\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nImportando os dados e vizualizando\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n#Vizualizar\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot(fill = \"gray\")+\n  geom_jitter(width = 0.1, size = 2)+\n  theme_few()\n\n\n\n\nRealizando a ANOVA\nA anova pode ser raalizada através da função aov() ou lm() do R básico. A função lm(), além de realizar&lt; pode ser utilizada para ajustar modelos lineares ao conjunto de dados, portanto é mais completa que a aov().\n\nanova_micelial &lt;- aov(tcm ~ especie, data = micelial)\n \nanova_micelial\n\nCall:\n   aov(formula = tcm ~ especie, data = micelial)\n\nTerms:\n                  especie Residuals\nSum of Squares  1.4695800 0.4679167\nDeg. of Freedom         4        25\n\nResidual standard error: 0.1368089\nEstimated effects may be unbalanced\n\n\nResumo dos resultados através da função summary():\n\nsummary(anova_micelial)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObtendo o quadro da ANOVA com a função anova():\n\nanova(anova_micelial)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nANOVA feita com a função lm():\n\nanova_micelial2 &lt;- lm(tcm ~ especie, data = micelial)\n\nanova_micelial2\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nCoefficients:\n(Intercept)  especieFaus  especieFcor  especieFgra  especieFmer  \n      1.572       -0.335       -0.250       -0.660       -0.145  \n\n\n\nsummary(anova_micelial2)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\n\nanova(anova_micelial2)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nA ANOVA possui várias pressuposições fundamentais que devem ser atendidas para que os resultados sejam válidos. Aqui iremos demonstrar diferentes meios de verificar estas presusuposições.\n\n\nOs resíduos (diferenças entre os valores observados e as médias dos grupos) devem seguir uma distribuição normal.\nVeja diferentes maneiras de como testar a normalidade dos resíduos do conjunto de dados submetido a ANOVA\nOpção 1: Teste de Shapiro\n\nshapiro.test(anova_micelial2$residuals) # H0 é de que os resíduos apresentam distribuição normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  anova_micelial2$residuals\nW = 0.9821, p-value = 0.8782\n\n\nOpção 2: Gráfico de histograma para os resíduos\n\nhist(anova_micelial2$residuals)\n\n\n\n\nOpção 3: Utilizando o pacote perfomance\n\nlibrary(performance)\n\ncheck_normality(anova_micelial2)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\n\n\n\n\nAs variâncias dos resíduos devem ser aproximadamente iguais entre os grupos. A violação dessa pressuposição pode levar a resultados incorretos, pois a ANOVA assume que a variabilidade dentro de cada grupo é similar.\nVeja maneiras diferentes de verificar esta premissa\nOpção 1: Teste de Bartlett\n\nbartlett.test(tcm ~ especie, data = micelial) # H0 é que a variâncias são homogêneas\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nOpção 2: Utilizando o pacote perfomance\n\ncheck_heteroscedasticity(anova_micelial2)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\n\n\n\n\nVocê pode utilizar o pacote performance para checar mais pressuposições com a função check_model():\n\nplot_presup &lt;- check_model(anova_micelial2)\n\nplot_presup\n\n\n\n\nO pacote DHARMA também pode ser utilizado para checar normalidade e homoscedasticidade\n\nlibrary(DHARMa)\n\nplot(simulateResiduals(anova_micelial2))\n\n\n\n\n\n\n\n\nQuando a ANOVA é significativa, isso indica que há pelo menos uma diferença significativa entre as médias dos grupos comparados. No entanto, a ANOVA não especifica quais grupos diferem entre si. Para identificar essas diferenças específicas, é necessário realizar testes de comparações múltiplas.\nUm teste amplamente utilizado é o Teste de Tukey, utilizado para comparações múltiplas entre todas as possíveis pares de médias.\nVeja como realizá-lo:\n\n#Demonstrando os agrupamentos de médias\nlibrary(emmeans)\nlibrary(multcomp)\n\nmedias_lm &lt;- emmeans(anova_micelial2, ~ especie) # Obtendo as médias do conjunto de dados\n\nmedias_lm\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\n\nA função cld() do pacote multcomp separa os grupos de média via Teste Tukey\n\ncld(medias_lm, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nE se as pressuposições não forem atendidas?\nNeste caso podemos aplicar diferentes transformações nos dados (raiz quadrada, logarítmica ou boxcox), para tentar atender às premissas de normalidade e homogeneidade das variâncias.\nVeremos as transformações para um novo conjunto de dados onde as premissas para a ANOVA não são atendidas:\n\nInseticida &lt;- InsectSprays\n\n\n\nTransformando os dados via raiz quadrada, realizando a ANOVA e testando as pressuposições, temos os seguintes chunks:\n\nInseticida &lt;- Inseticida |&gt; \n  mutate(count2 = sqrt(count))\n\n# Vizualizando após a transformação\nInseticida |&gt; \n  ggplot(aes(spray, count2, fill= spray))+\n  geom_boxplot()+\n  geom_jitter(width = 0.05, size = 2)+\n  theme_few()+\n  scale_fill_few()+\n  theme(legend.title = element_blank(), legend.position = \"none\")\n\n\n\n\n\nm2 &lt;- lm (count2 ~ spray, data = Inseticida)\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplot(simulateResiduals(m2))\n\n\n\n\nA transformação logarítima pode ser feita substituindo a função sqrt() por log().\n\n\n\nA transformação Box-Cox é definida por uma família de transformações parametrizadas por lambda (λ)\nProcesso de aplicação consiste em estimar lambda (λ), calculando a transformação para uma série de valores possíveis de λ (geralmente de -2 a 2, por exemplo) e escolhendo aquela que maximiza a normalidade dos dados transformados. Posteriormente, aplicar a transformação aos dados originais y^(λ), onde y é a variável de interesse.\nO pacote MASS possui as funções úteis para realizar essa transformação. Veja:\n\nlibrary(MASS)\n\nb &lt;- boxcox(lm(Inseticida$count+0.1 ~ 1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda = 0.5\n\nInseticida$count3 &lt;-(Inseticida$count ^ lambda - 1) / lambda\n\n\nhist(Inseticida$count3)\n\n\n\n\n\nm3 &lt;- lm (count3 ~ spray, data = Inseticida)\n\nplot(simulateResiduals(m3))\n\n\n\n\n\n\n\nSe isso não for eficaz, podem ser utilizados testes não paramétricos, como o teste de Kruskal-Wallis, que não assume normalidade dos dados.\n\nlibrary(agricolae)\nkruskal.test(count ~ spray, data = Inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nm3 &lt;- kruskal(Inseticida$count,\n        Inseticida$spray,\n        group = TRUE)\n\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none Inseticida$spray   6  0.05\n\n$means\n  Inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  Inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\n\n\n\nOs modelos lineares não generalizados permitem modelar relações entre variáveis dependentes e independentes, mesmo quando a distribuição dos dados não é normal ou quando a variância não é constante.\nVocê pode utilizar a função glm() do R básico, identificando a distribuição que mais adequa aos seus dados no argumento family =.\nAqui assumimos a distribuição de poisson.\n\nm4 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = Inseticida)\n\nm4\n\n\nCall:  glm(formula = count ~ spray, family = poisson, data = Inseticida)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n    2.67415      0.05588     -1.94018     -1.08152     -1.42139      0.13926  \n\nDegrees of Freedom: 71 Total (i.e. Null);  66 Residual\nNull Deviance:      409 \nResidual Deviance: 98.33    AIC: 376.6\n\n\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\n\n\nplot(simulateResiduals(m4))\n\n\n\n\n\nmedias4 &lt;- emmeans(m4, ~ spray, type = \"response\")\n\ncld(medias4, Letters = letters)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  a    \n E      3.50 0.540 Inf      2.59      4.74  ab   \n D      4.92 0.640 Inf      3.81      6.35   b   \n A     14.50 1.099 Inf     12.50     16.82    c  \n B     15.33 1.130 Inf     13.27     17.72    c  \n F     16.67 1.179 Inf     14.51     19.14    c  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_6.1.html#anova-em-dic",
    "href": "R_codes/Aula_6.1.html#anova-em-dic",
    "title": "Análise de Variância (ANOVA)",
    "section": "",
    "text": "A ANOVA é uma técnica estatística normalmente utilizada para comparar as médias de três ou mais grupos distintos e determinar se existem diferenças estatisticamente significativas entre essas médias. A ANOVA é particularmente útil quando se deseja testar a hipótese de que várias populações têm a mesma média.\nAqui veremos como realizar a ANOVA para dados provenientes de experimentos conduzidos em DIC (Delineamento Inteiramente Casualizado) que é uma técnica estatística frequentemente utilizada em experimentos para comparar tratamentos onde a distribuição dos tratamentos às unidades experimentais é feita inteiramente ao acaso. Como não faz restrições na casualização, o uso do DIC pressupõe que as unidades experimentais estão sob condições homogêneas.\nPacotes utilizados:\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nImportando os dados e vizualizando\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n#Vizualizar\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot(fill = \"gray\")+\n  geom_jitter(width = 0.1, size = 2)+\n  theme_few()\n\n\n\n\nRealizando a ANOVA\nA anova pode ser raalizada através da função aov() ou lm() do R básico. A função lm(), além de realizar&lt; pode ser utilizada para ajustar modelos lineares ao conjunto de dados, portanto é mais completa que a aov().\n\nanova_micelial &lt;- aov(tcm ~ especie, data = micelial)\n \nanova_micelial\n\nCall:\n   aov(formula = tcm ~ especie, data = micelial)\n\nTerms:\n                  especie Residuals\nSum of Squares  1.4695800 0.4679167\nDeg. of Freedom         4        25\n\nResidual standard error: 0.1368089\nEstimated effects may be unbalanced\n\n\nResumo dos resultados através da função summary():\n\nsummary(anova_micelial)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObtendo o quadro da ANOVA com a função anova():\n\nanova(anova_micelial)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nANOVA feita com a função lm():\n\nanova_micelial2 &lt;- lm(tcm ~ especie, data = micelial)\n\nanova_micelial2\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nCoefficients:\n(Intercept)  especieFaus  especieFcor  especieFgra  especieFmer  \n      1.572       -0.335       -0.250       -0.660       -0.145  \n\n\n\nsummary(anova_micelial2)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\n\nanova(anova_micelial2)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "R_codes/Aula_6.1.html#pressuposições-da-anova-e-testes-de-médias",
    "href": "R_codes/Aula_6.1.html#pressuposições-da-anova-e-testes-de-médias",
    "title": "Análise de Variância (ANOVA)",
    "section": "",
    "text": "A ANOVA possui várias pressuposições fundamentais que devem ser atendidas para que os resultados sejam válidos. Aqui iremos demonstrar diferentes meios de verificar estas presusuposições.\n\n\nOs resíduos (diferenças entre os valores observados e as médias dos grupos) devem seguir uma distribuição normal.\nVeja diferentes maneiras de como testar a normalidade dos resíduos do conjunto de dados submetido a ANOVA\nOpção 1: Teste de Shapiro\n\nshapiro.test(anova_micelial2$residuals) # H0 é de que os resíduos apresentam distribuição normal\n\n\n    Shapiro-Wilk normality test\n\ndata:  anova_micelial2$residuals\nW = 0.9821, p-value = 0.8782\n\n\nOpção 2: Gráfico de histograma para os resíduos\n\nhist(anova_micelial2$residuals)\n\n\n\n\nOpção 3: Utilizando o pacote perfomance\n\nlibrary(performance)\n\ncheck_normality(anova_micelial2)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\n\n\n\n\nAs variâncias dos resíduos devem ser aproximadamente iguais entre os grupos. A violação dessa pressuposição pode levar a resultados incorretos, pois a ANOVA assume que a variabilidade dentro de cada grupo é similar.\nVeja maneiras diferentes de verificar esta premissa\nOpção 1: Teste de Bartlett\n\nbartlett.test(tcm ~ especie, data = micelial) # H0 é que a variâncias são homogêneas\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nOpção 2: Utilizando o pacote perfomance\n\ncheck_heteroscedasticity(anova_micelial2)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\n\n\n\n\nVocê pode utilizar o pacote performance para checar mais pressuposições com a função check_model():\n\nplot_presup &lt;- check_model(anova_micelial2)\n\nplot_presup\n\n\n\n\nO pacote DHARMA também pode ser utilizado para checar normalidade e homoscedasticidade\n\nlibrary(DHARMa)\n\nplot(simulateResiduals(anova_micelial2))"
  },
  {
    "objectID": "R_codes/Aula_6.1.html#testes-de-comparações-múltiplas",
    "href": "R_codes/Aula_6.1.html#testes-de-comparações-múltiplas",
    "title": "Análise de Variância (ANOVA)",
    "section": "",
    "text": "Quando a ANOVA é significativa, isso indica que há pelo menos uma diferença significativa entre as médias dos grupos comparados. No entanto, a ANOVA não especifica quais grupos diferem entre si. Para identificar essas diferenças específicas, é necessário realizar testes de comparações múltiplas.\nUm teste amplamente utilizado é o Teste de Tukey, utilizado para comparações múltiplas entre todas as possíveis pares de médias.\nVeja como realizá-lo:\n\n#Demonstrando os agrupamentos de médias\nlibrary(emmeans)\nlibrary(multcomp)\n\nmedias_lm &lt;- emmeans(anova_micelial2, ~ especie) # Obtendo as médias do conjunto de dados\n\nmedias_lm\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\n\nA função cld() do pacote multcomp separa os grupos de média via Teste Tukey\n\ncld(medias_lm, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_6.1.html#transformação-de-dados-e-alternativas-não-paramétricas-da-anova",
    "href": "R_codes/Aula_6.1.html#transformação-de-dados-e-alternativas-não-paramétricas-da-anova",
    "title": "Análise de Variância (ANOVA)",
    "section": "",
    "text": "E se as pressuposições não forem atendidas?\nNeste caso podemos aplicar diferentes transformações nos dados (raiz quadrada, logarítmica ou boxcox), para tentar atender às premissas de normalidade e homogeneidade das variâncias.\nVeremos as transformações para um novo conjunto de dados onde as premissas para a ANOVA não são atendidas:\n\nInseticida &lt;- InsectSprays\n\n\n\nTransformando os dados via raiz quadrada, realizando a ANOVA e testando as pressuposições, temos os seguintes chunks:\n\nInseticida &lt;- Inseticida |&gt; \n  mutate(count2 = sqrt(count))\n\n# Vizualizando após a transformação\nInseticida |&gt; \n  ggplot(aes(spray, count2, fill= spray))+\n  geom_boxplot()+\n  geom_jitter(width = 0.05, size = 2)+\n  theme_few()+\n  scale_fill_few()+\n  theme(legend.title = element_blank(), legend.position = \"none\")\n\n\n\n\n\nm2 &lt;- lm (count2 ~ spray, data = Inseticida)\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nplot(simulateResiduals(m2))\n\n\n\n\nA transformação logarítima pode ser feita substituindo a função sqrt() por log().\n\n\n\nA transformação Box-Cox é definida por uma família de transformações parametrizadas por lambda (λ)\nProcesso de aplicação consiste em estimar lambda (λ), calculando a transformação para uma série de valores possíveis de λ (geralmente de -2 a 2, por exemplo) e escolhendo aquela que maximiza a normalidade dos dados transformados. Posteriormente, aplicar a transformação aos dados originais y^(λ), onde y é a variável de interesse.\nO pacote MASS possui as funções úteis para realizar essa transformação. Veja:\n\nlibrary(MASS)\n\nb &lt;- boxcox(lm(Inseticida$count+0.1 ~ 1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda = 0.5\n\nInseticida$count3 &lt;-(Inseticida$count ^ lambda - 1) / lambda\n\n\nhist(Inseticida$count3)\n\n\n\n\n\nm3 &lt;- lm (count3 ~ spray, data = Inseticida)\n\nplot(simulateResiduals(m3))\n\n\n\n\n\n\n\nSe isso não for eficaz, podem ser utilizados testes não paramétricos, como o teste de Kruskal-Wallis, que não assume normalidade dos dados.\n\nlibrary(agricolae)\nkruskal.test(count ~ spray, data = Inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nm3 &lt;- kruskal(Inseticida$count,\n        Inseticida$spray,\n        group = TRUE)\n\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none Inseticida$spray   6  0.05\n\n$means\n  Inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  Inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\n\n\n\nOs modelos lineares não generalizados permitem modelar relações entre variáveis dependentes e independentes, mesmo quando a distribuição dos dados não é normal ou quando a variância não é constante.\nVocê pode utilizar a função glm() do R básico, identificando a distribuição que mais adequa aos seus dados no argumento family =.\nAqui assumimos a distribuição de poisson.\n\nm4 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = Inseticida)\n\nm4\n\n\nCall:  glm(formula = count ~ spray, family = poisson, data = Inseticida)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n    2.67415      0.05588     -1.94018     -1.08152     -1.42139      0.13926  \n\nDegrees of Freedom: 71 Total (i.e. Null);  66 Residual\nNull Deviance:      409 \nResidual Deviance: 98.33    AIC: 376.6\n\n\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\n\n\nplot(simulateResiduals(m4))\n\n\n\n\n\nmedias4 &lt;- emmeans(m4, ~ spray, type = \"response\")\n\ncld(medias4, Letters = letters)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  a    \n E      3.50 0.540 Inf      2.59      4.74  ab   \n D      4.92 0.640 Inf      3.81      6.35   b   \n A     14.50 1.099 Inf     12.50     16.82    c  \n B     15.33 1.130 Inf     13.27     17.72    c  \n F     16.67 1.179 Inf     14.51     19.14    c  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "R_codes/Aula_4.html",
    "href": "R_codes/Aula_4.html",
    "title": "Obtendo dados através do copiar e colar",
    "section": "",
    "text": "Para obter dados diretamente de tabelas em sites ou qualquer outro documento digital e criar data.frames no R você pode utilizar dois pacotes, o tibble e o datapasta. Ambos compilam os dados copiados e organizam mantendo o formato original dentro do chunk, uma maneira simples que otimiza o seu Ctrl + C & Ctrl + V.\nUsando o datapasta, após copiar três colunas de dados de uma planilha, basta clicar em Addins... e Past as data.frame.\n\nlibrary(datapasta)\n\ndat &lt;- data.frame(\n  stringsAsFactors = FALSE, # 'stringsAsFactors' converte variáveis em um data frame para fatores\n              trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                       \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\n                       \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                       \"control\",\"control\",\"control\"),\n               rep = c(1L,2L,3L,4L,5L,6L,7L,8L,\n                       9L,10L,1L,2L,3L,4L,5L,6L,7L,8L,9L,10L),\n              comp = c(9,12.5,10,8,13.2,11,10.8,\n                       9.5,10.8,10.4,13.72,15.91,15.7,14.2,15.9,16.54,\n                       18,14.4,16.41,16)\n)\ndat\n\n      trat rep  comp\n1      Mg2   1  9.00\n2      Mg2   2 12.50\n3      Mg2   3 10.00\n4      Mg2   4  8.00\n5      Mg2   5 13.20\n6      Mg2   6 11.00\n7      Mg2   7 10.80\n8      Mg2   8  9.50\n9      Mg2   9 10.80\n10     Mg2  10 10.40\n11 control   1 13.72\n12 control   2 15.91\n13 control   3 15.70\n14 control   4 14.20\n15 control   5 15.90\n16 control   6 16.54\n17 control   7 18.00\n18 control   8 14.40\n19 control   9 16.41\n20 control  10 16.00\n\n\nAgora, com o pacote tibble, basta clicar em Addins... e Past as tribble.\n\nlibrary(tibble)\n\ndat2 &lt;- tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,  12.5,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,  13.2,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,  10.8,\n      \"Mg2\",   8L,   9.5,\n      \"Mg2\",   9L,  10.8,\n      \"Mg2\",  10L,  10.4,\n  \"control\",   1L, 13.72,\n  \"control\",   2L, 15.91,\n  \"control\",   3L,  15.7,\n  \"control\",   4L,  14.2,\n  \"control\",   5L,  15.9,\n  \"control\",   6L, 16.54,\n  \"control\",   7L,    18,\n  \"control\",   8L,  14.4,\n  \"control\",   9L, 16.41,\n  \"control\",  10L,    16\n  )\ndat2\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\n# 'dat' e 'dat2' são iguais, o que muda é a forma de vizualização dos dados no chunk.\n\nVeja mais esse exemplo, com o tribble, de um conjunto de dados disponível aqui:\n\nvisitas &lt;- tribble(\n        ~`codigo`,            ~país,    ~`n2`,\n               1L,         \"Brazil\",    4303L,\n               2L,     \"Mozambique\",      43L,\n               3L,       \"Portugal\",      33L,\n               4L,  \"United States\",      23L,\n               5L,         \"Angola\",      19L,\n               6L,          \"Spain\",      16L,\n               7L,      \"(not set)\",      12L,\n               8L,       \"Colombia\",       8L,\n               9L,        \"Germany\",       5L,\n              10L,        \"Hungary\",       5L,\n              11L, \"United Kingdom\",       5L,\n              12L,    \"Netherlands\",       4L,\n              13L,        \"Ecuador\",       3L,\n              14L,         \"France\",       3L,\n              15L,          \"Chile\",       2L,\n              16L,       \"Paraguay\",       2L,\n              17L,           \"Peru\",       2L,\n              18L,      \"Argentina\",       1L,\n              19L,        \"Austria\",       1L,\n              20L,        \"Bolivia\",       1L,\n              21L,     \"Cape Verde\",       1L,\n              22L,          \"China\",       1L,\n              23L,          \"Egypt\",       1L,\n              24L,        \"Finland\",       1L,\n              25L,          \"India\",       1L,\n              26L,          \"Italy\",       1L,\n              27L,       \"Malaysia\",       1L,\n              28L,       \"Pakistan\",       1L,\n              29L,         \"Poland\",       1L,\n              30L,      \"Singapore\",       1L,\n              31L,    \"Timor-Leste\",       1L,\n              32L,        \"Uruguay\",       1L\n             )\nvisitas\n\n# A tibble: 32 × 3\n   codigo país             n2\n    &lt;int&gt; &lt;chr&gt;         &lt;int&gt;\n 1      1 Brazil         4303\n 2      2 Mozambique       43\n 3      3 Portugal         33\n 4      4 United States    23\n 5      5 Angola           19\n 6      6 Spain            16\n 7      7 (not set)        12\n 8      8 Colombia          8\n 9      9 Germany           5\n10     10 Hungary           5\n# ℹ 22 more rows"
  },
  {
    "objectID": "R_codes/Aula_4.html#montando-gráfico-à-partir-de-um-data-frame-criado",
    "href": "R_codes/Aula_4.html#montando-gráfico-à-partir-de-um-data-frame-criado",
    "title": "Obtendo dados através do copiar e colar",
    "section": "Montando gráfico à partir de um data frame criado",
    "text": "Montando gráfico à partir de um data frame criado\n\nlibrary(tidyverse)\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\nFazendo o uso da função pivot_longer() para modificar a aquitetura dos dados de uma maneira em que cada observação ocupa uma linha separada em uma tabela, e diferentes medidas ou variáveis sejam armazenadas em colunas diferentes, o “formato longo”, e criando um gráfico de linhas e pontos.\n\npepper |&gt;\n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\",\n           x = 12,\n           y = 0.79,\n           label = \"1\")+\nannotate(geom = \"text\",\n           x = 26,\n           y = 0.80,\n           label = \"2\")+\n  annotate(geom = \"text\",\n           x = 47,\n           y = 0.76,\n           label = \"3\")+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "R_codes/Aula_4.html#tabela-de-contigência",
    "href": "R_codes/Aula_4.html#tabela-de-contigência",
    "title": "Obtendo dados através do copiar e colar",
    "section": "Tabela de Contigência",
    "text": "Tabela de Contigência\nVeja como criar uma tabela de contigência à partir de dados disponíveis em um documento online no formato CSV.\nO pacote janitor será usado para limpeza e organização de dados. A função tabyl() cria tabelas de frequência cruzada. Aqui, iremos criar uma tabela de contagem de combinações únicas das variáveis “cultivar” e “farm_management”.\n\nlibrary(ggthemes)\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\nlibrary(janitor)\ncr |&gt; \n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management,\n             label = n))+\n  geom_col(position = \"dodge2\")+\n  scale_fill_canva()+\n  theme_bw()+\n  theme(strip.text.x = element_blank(),\n        legend.position = \"top\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")\n\n\n\n\nOs dados são de uma pesquisa sobre ferrugem do café na Etiópia e contam as ocorrências de diferentes combinações de métodos de gestão agrícola (farm_management) e cultivares (cultivar), e visualiza essas contagens em um gráfico de barras facetado por cultivar, com barras coloridas por método de gestão agrícola."
  },
  {
    "objectID": "R_codes/Aula_4.html#medidas-de-tendência-central-em-gráficos",
    "href": "R_codes/Aula_4.html#medidas-de-tendência-central-em-gráficos",
    "title": "Obtendo dados através do copiar e colar",
    "section": "Medidas de tendência central em gráficos",
    "text": "Medidas de tendência central em gráficos\nAqui veremos uma maneira de, à partir de dados importados, ralizar cálculos estatísticos (média e desvio padrão) agrupados por uma variável, e então visualiza os resultados em um gráfico.\nVamos usar o geom_errorbar() para adicionar barras de erro ao gráfico, representando a variação de um desvio padrão acima e abaixo da média, com largura das barras definida como 0.1.\n\nlibrary(gsheet)\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nmg |&gt; \n  group_by(trat) |&gt; \n  summarise(mean_comp = mean(comp), sd_comp = sd(comp))|&gt; \n  ggplot(aes(trat, mean_comp))+\n  geom_point(size = 3)+\n  ylim(5,20)+ # Define os limites do eixo y de 5 a 20\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp), width = 0.1)+\n  annotate (geom = \"text\",\n           x = 1, y = 17.5,\n           label = '*')\n\n\n\n# 'group_by(trat)': Agrupa os dados pela coluna trat (tratamento).\n# 'summarise(mean_comp = mean(comp), sd_comp = sd(comp))': Calcula a média (mean()) e o desvio padrão (sd()) da coluna comp para cada grupo de trat.\n\nCom os mesmos dados, podemos ainda, criae um gráfico de dispersão (jitter plot), que mostra a distribuição dos valores de comp para diferentes níveis de tratatamento.\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.1)"
  },
  {
    "objectID": "R_codes/Aula_2.html",
    "href": "R_codes/Aula_2.html",
    "title": "Características dos Pacotes em R",
    "section": "",
    "text": "Um pacote é uma coleção de funções, dados, e documentação organizada em uma estrutura padronizada, que estende as capacidades básicas da linguagem R.\nOs pacotes no RStudio podem ser estalados de diversos repositórios online. Eles possuem funções, conjunto de dados que podem ser usados para exemplos ou testes e documentos com tutoriais para explicar o uso das funções e os dados que estão incluídos no pacote.\nExemplos de Pacotes Populares:\nggplot: Para visualização de dados.\ndplyr: Para manipulação de dados.\ntidyr: Para organização de dados.\nTodos estes pacotes serão utilizados nas análises realizadas aqui. Existe um pacote que abriga todos estes e mais outros, o tydiverse. Um universo de ferramentas bastante utilizadas em análise de dados.\n\n\nA instalação de pacotes pode ser feita através do menu: Tools \\&gt; Install packages..., ou ainda:\n\n#install.packages(nome do pacote de interesse)\n\nVale ressaltar que é necessário ter uma conexão estável com a internet para instalar um pacote.\nPara instalar o tydiverse:\n\ninstall.packages(\"tidyverse\", repos = \"https://cran.r-project.org\") \n\n#'repos =' indica o repositório online de onde o pacote está sendo baixado, não necessariamente precisa ser utilizado\n\n\n\n\nAntes de usar qualquer função de um pacote, é necessário carregá-lo.\nPara carregar um pacote instalado e usá-lo na sessão atual do R, utiliza-se a função library(). Por exemplo, para carregar o tidyverse:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\nComo já mencionamos, os pacotes R estão disponíveis em repositórios online. O repositório mais conhecido e utilizado é o CRAN (Comprehensive R Archive Network). No entanto, existem vários repositórios importantes que oferecem uma vasta gama de pacotes R.\nVeja como utilizar dois pacotes CRAN para para instalar pacotes de outros repositórios:\n\nlibrary(pak)\n#pak::pkg_install(\"Icens\")\n#pak::pkg_install(\"emdelponte/r4pde\")\n\nlibrary(remotes)\n#remotes::install_github(\"emdelponte/r4pde\")"
  },
  {
    "objectID": "R_codes/Aula_2.html#instalando-um-pacote",
    "href": "R_codes/Aula_2.html#instalando-um-pacote",
    "title": "Características dos Pacotes em R",
    "section": "",
    "text": "A instalação de pacotes pode ser feita através do menu: Tools \\&gt; Install packages..., ou ainda:\n\n#install.packages(nome do pacote de interesse)\n\nVale ressaltar que é necessário ter uma conexão estável com a internet para instalar um pacote.\nPara instalar o tydiverse:\n\ninstall.packages(\"tidyverse\", repos = \"https://cran.r-project.org\") \n\n#'repos =' indica o repositório online de onde o pacote está sendo baixado, não necessariamente precisa ser utilizado"
  },
  {
    "objectID": "R_codes/Aula_2.html#carregando-um-pacote",
    "href": "R_codes/Aula_2.html#carregando-um-pacote",
    "title": "Características dos Pacotes em R",
    "section": "",
    "text": "Antes de usar qualquer função de um pacote, é necessário carregá-lo.\nPara carregar um pacote instalado e usá-lo na sessão atual do R, utiliza-se a função library(). Por exemplo, para carregar o tidyverse:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "R_codes/Aula_2.html#pacotes-r-em-outros-repositórios",
    "href": "R_codes/Aula_2.html#pacotes-r-em-outros-repositórios",
    "title": "Características dos Pacotes em R",
    "section": "",
    "text": "Como já mencionamos, os pacotes R estão disponíveis em repositórios online. O repositório mais conhecido e utilizado é o CRAN (Comprehensive R Archive Network). No entanto, existem vários repositórios importantes que oferecem uma vasta gama de pacotes R.\nVeja como utilizar dois pacotes CRAN para para instalar pacotes de outros repositórios:\n\nlibrary(pak)\n#pak::pkg_install(\"Icens\")\n#pak::pkg_install(\"emdelponte/r4pde\")\n\nlibrary(remotes)\n#remotes::install_github(\"emdelponte/r4pde\")"
  },
  {
    "objectID": "R_codes/Aula_1.html",
    "href": "R_codes/Aula_1.html",
    "title": "Projetos e Diretórios",
    "section": "",
    "text": "Criar um projeto no RStudio para análise de dados oferece diversas vantagens, como melhor organização e gerenciamento de arquivos, ambiente de trabalho isolado e reprodutível, e integração com sistemas de controle de versão como Git. Facilita a colaboração e partilha de projetos, permitindo que todas as dependências e estrutura de diretórios sejam consistentes. A automatização de tarefas através de scripts, a facilidade de navegação e a manutenção de um diretório de trabalho consistente melhoram a eficiência. Além disso, as configurações específicas do projeto são salvas e podem ser facilmente restauradas, proporcionando um ambiente de análise de dados organizado e eficaz.\nPara criar um projeto no RStudio, abra o programa e clique em Project: (None) no canto superior direito, selecionando New Project... escolha New Directory para criar um projeto em um novo diretório ou Existing Directory para usar uma pasta existente. Para a maioria dos casos, selecione New Project, insira o nome do diretório e escolha o local onde o diretório será criado. Clique em Create Project e o RStudio configurará e abrirá automaticamente o novo projeto, permitindo que você adicione arquivos e scripts conforme necessário para sua análise de dados."
  },
  {
    "objectID": "R_codes/Aula_1.html#estrutura-de-um-chunk",
    "href": "R_codes/Aula_1.html#estrutura-de-um-chunk",
    "title": "Projetos e Diretórios",
    "section": "Estrutura de um Chunk",
    "text": "Estrutura de um Chunk\nBom, para resumir…\nIsso: ‘```{r …}’; inicia um chunk de código R.\nE isso: ‘```’; termina o chunk.\nVocê pode criar um chunk utilizando o atalho de teclado Ctrl + Alt + I (Windows/Linux) ou Cmd + Option + I (Mac) para inserir um chunk de código. Para executar o código dentro desse chunk, com o mesmo selecionado, pressione Ctrl + Enter. Para deixar comentários dentro do chunk adicone # antes da frase.\n\n# Este é um exemplo de chunk\n\n# Você pode executar diversos códigos e obter respostas:\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "R_codes/Aula_1.html#aprendendo-a-atribuir-valores",
    "href": "R_codes/Aula_1.html#aprendendo-a-atribuir-valores",
    "title": "Projetos e Diretórios",
    "section": "Aprendendo a atribuir valores",
    "text": "Aprendendo a atribuir valores\nVocê pode criar objetos atribuindo valores à eles. Os valores adiconados irão aparecer na aba Enviroment.\n\nA &lt;- 1\nB &lt;- 2\nC &lt;- 3\n\n# Para vizualizar o valor do objeto selecione-o e execute o código.\n\nC\n\n[1] 3"
  },
  {
    "objectID": "R_codes/Aula_1.html#fazendo-operações",
    "href": "R_codes/Aula_1.html#fazendo-operações",
    "title": "Projetos e Diretórios",
    "section": "Fazendo operações",
    "text": "Fazendo operações\nVocê pode fazer operações com números e também com os objetos criados que assumem os valores atribuidos:\n\nA + 2\n\n[1] 3"
  },
  {
    "objectID": "R_codes/Aula_1.html#criando-vetores",
    "href": "R_codes/Aula_1.html#criando-vetores",
    "title": "Projetos e Diretórios",
    "section": "Criando vetores",
    "text": "Criando vetores\nVetores são objetos com vários valores. Você pode utilizar c() para indicar a combinação.\nExemplo de vetores:\n\n# Para dados numéricos\n\nD &lt;- c(2, 4, 6, 8, 10)\n\n# Para dados do tipo caracteres.\n\nS &lt;- c(\"une\", \"dune\", \"tê\", \"salamê\", \"minguê\")\n\n# Adicionar aspas faz com o que os elementes de um vetor de dados sejam lidos como caracteres mesmo que se tratem de números.\n\ncomp &lt;- c( \"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\n\n# É ideal que um vetor agrupe o mesmo tipo de dado!\n\n# Agora, é só vizualizar:\n\ncomp\n\n [1] \"9\"     \"12.5\"  \"10\"    \"8\"     \"13.2\"  \"11\"    \"10.8\"  \"9.5\"   \"10.8\" \n[10] \"10.4\"  \"13.72\" \"15.91\" \"15.7\"  \"14.2\"  \"15.9\"  \"16.54\" \"18\"    \"14.4\" \n[19] \"16.41\" \"16\""
  },
  {
    "objectID": "R_codes/Aula_1.html#criando-um-data-frame",
    "href": "R_codes/Aula_1.html#criando-um-data-frame",
    "title": "Projetos e Diretórios",
    "section": "Criando um data frame",
    "text": "Criando um data frame\nUm dataframe é uma estrutura de dados bidimensional, semelhante a uma tabela, amplamente utilizada na linguagem R. Ele permite armazenar e manipular diferentes tipos de dados tabulares de forma eficiente.\nExemplo de um dataframe:\n\ndataf &lt;- data.frame(palavras = S, números = D)\n\n\ndataf\n\n  palavras números\n1      une       2\n2     dune       4\n3       tê       6\n4   salamê       8\n5   minguê      10"
  },
  {
    "objectID": "R_codes/Aula_1.html#como-pedir-ajuda",
    "href": "R_codes/Aula_1.html#como-pedir-ajuda",
    "title": "Projetos e Diretórios",
    "section": "Como pedir ajuda",
    "text": "Como pedir ajuda\nVocê percebeu que utilizou um comando chamado data.frame para criar o seu dataframe, certo? Pois bem, este comando é uma função base do software R. Ao longo das nossas aulas vamos nos deparar com diversas funções diferentes.\nFicou com dúvida sobre o uso de alguma função? Tem uma função que pode te ajudar! Basta digitar help(), entre parênteses você digita o nome da função sobre a qual você tem duvida.\nVeja o exemplo:\n\nhelp(data.frame)\n\nstarting httpd help server ... done\n\n# Isso faz com que apareça informações sobre a função na aba de ajuda \"help\"."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olá!",
    "section": "",
    "text": "Seja muito bem vindo! Espero que esteja ansioso para mergulhar no mundo da análise e vizualização de dados provenientes da ciência que estuda as Doenças de Plantas. Este é o Quarto website para disponibilizar as aulas em RStudio da disciplina FIP 606, oferecida no Programa de Pós-graduação em Fitopatologia da Universidade Federal de Viçosa pelo professor Emerson M Del Ponte. As aulas são códigos comentados e estão organizadas em “Fundamentos”, “Análise Exploratória” e “Análise de Dados”. O objetivo do website é compartilhar o conhecimento aprendido com outros colegas da área e despertar o interesse daqueles que ainda não conhecem o tema.\n\nVem comigo!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "R_codes/apresentação.html",
    "href": "R_codes/apresentação.html",
    "title": "É um prazer conhecê-lo!",
    "section": "",
    "text": "É um prazer conhecê-lo!\n\nMeu nome é David Aimar e eu sou o criador deste site. Sou formado em Engenharia Agronômica pelo Instituto Federal de Educação Ciências e Tecnologia do Tocantins, Campus Araguatins (2022), atualmente sou estudante de mestrado do Programa de Pós-Graduação em Fitopatologia da Universidade Federal de Viçosa e integro o Laboratório de Manejo Integrado de Doenças de Plantas sob supervisão do professor Dr. Franklin Jackson Machado.\nÉ ótimo tê-lo aqui! Espero que faça um bom uso do conteúdo disponibilizado.\nMuito obrigado!"
  },
  {
    "objectID": "R_codes/Aula_10.html",
    "href": "R_codes/Aula_10.html",
    "title": "Criação de Mapas",
    "section": "",
    "text": "Pacotes carregados:\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(ggspatial)\nlibrary(plotly)\nlibrary(leaflet)\nlibrary(r4pde)\nlibrary(ggthemes)\n\n\n\nPara plotar o mapa do pais, usa-se a função ne_countries():\n\nBRA &lt;- ne_states (country = \"Brazil\",\n                  returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\nggplot(BRA) + geom_sf(fill = \"white\")\n\n\n\n\n\n\n\nBasta apenas fazer o uso da função filter():\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nggplot(MG) + geom_sf(fill = \"white\")\n\n\n\n\n\nTO &lt;- BRA |&gt; \n  filter(name_en == \"Tocantins\")\n\nggplot(TO) + geom_sf(fill = \"white\")\n\n\n\n\n\n\n\nDados que contém latitude e longidtude podem ter repostas de outras variáveis adicionadas aos mapas criados no R.\nVeja o exemplo para incidência de ferrugem asiática da soja:\n\nsbr &lt;- RustSoybean\nsbr |&gt; \n  ggplot(aes(longitude, latitude)) +\n  geom_point() +\n  coord_sf()\n\n\n\n\n\nbra &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\",\n                      color = \"black\",\n                      linewidth = 0.5) +\n  geom_point( data = sbr, aes(longitude, latitude),\n              color = \"red\") +\n  theme_map() +\n  annotation_north_arrow(which_north = \"grid\")\nbra\n\n\n\n\n\n\n\nAtravés da função ggplotly() é possível criar mapas em quadros dinâmicos com interface que permite movimento, zoom e outras ferramentas de exploração.\n\nggplotly(bra)\n\n\n\n\n\nConfigurando um mapa interativo usando o pacote leaflet, com base na localização especificada (longitude e latitude de Viçosa, MG, Brasil):\n\nViçosa &lt;- leaflet() |&gt; \n  addTiles() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5)\n\nViçosa\n\n\n\n\n\nAdicionando os dados de incidência da ferrugem asiática da soja ao mapa interativo\n\nViçosa_2 &lt;- leaflet(sbr) |&gt; \n  addTiles() |&gt; \n  addCircleMarkers(radius = 2)\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\nViçosa_2\n\n\n\n\n\n\n\n\nCombinando diferentes funcionalidades de visualização geoespacial e estatística podemos criar um gráfico interativo e informativo que mostra pontos geográficos e informações sobre a predominância de algumas doenças.\n\nlibrary(ggrepel) # Para adicionar textos que não se sobreponham aos pontos\nlibrary(scatterpie) # # Para criar gráficos de torta dispersos\n\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nBra_2 &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\", color = \"black\", linewidth = 0.5) +\n  coord_sf()+\n  geom_point(data = mapa, aes(lon, lat))+ # Plota pontos geoespaciais usando coordenadas de longitude e latitude do objeto 'mapa'.\n  geom_scatterpie(aes(x=lon, y=lat, r = 0.6),\n                  alpha = 0.8, color = NA, data = mapa,\n                  cols = c (\"DFC\",\n                            \"MA\",\n                            \"FER\",\n                            \"ANTR\",\n                            \"OIDIO\"))+ # Cria os gráficos de pizza\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                  size = 2, nudge_x = 0.2, nudge_y = 0.27, color = 'gray70', family = \"Arial\")+ # Adiciona rótulos de texto aos pontos, usando a coluna 'Local' para etiquetar cada ponto\n  scale_fill_calc()+\n  theme_map()+ \n  labs(x = \"Longitude\", y = \"Laititude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(family = \"Arieal\", size = 8))\n\nBra_2"
  },
  {
    "objectID": "R_codes/Aula_10.html#mapa-de-países",
    "href": "R_codes/Aula_10.html#mapa-de-países",
    "title": "Criação de Mapas",
    "section": "",
    "text": "Para plotar o mapa do pais, usa-se a função ne_countries():\n\nBRA &lt;- ne_states (country = \"Brazil\",\n                  returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\nggplot(BRA) + geom_sf(fill = \"white\")"
  },
  {
    "objectID": "R_codes/Aula_10.html#filtrando-mapas-por-unidades-federativas",
    "href": "R_codes/Aula_10.html#filtrando-mapas-por-unidades-federativas",
    "title": "Criação de Mapas",
    "section": "",
    "text": "Basta apenas fazer o uso da função filter():\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nggplot(MG) + geom_sf(fill = \"white\")\n\n\n\n\n\nTO &lt;- BRA |&gt; \n  filter(name_en == \"Tocantins\")\n\nggplot(TO) + geom_sf(fill = \"white\")"
  },
  {
    "objectID": "R_codes/Aula_10.html#adicionando-elementos-aos-mapas",
    "href": "R_codes/Aula_10.html#adicionando-elementos-aos-mapas",
    "title": "Criação de Mapas",
    "section": "",
    "text": "Dados que contém latitude e longidtude podem ter repostas de outras variáveis adicionadas aos mapas criados no R.\nVeja o exemplo para incidência de ferrugem asiática da soja:\n\nsbr &lt;- RustSoybean\nsbr |&gt; \n  ggplot(aes(longitude, latitude)) +\n  geom_point() +\n  coord_sf()\n\n\n\n\n\nbra &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\",\n                      color = \"black\",\n                      linewidth = 0.5) +\n  geom_point( data = sbr, aes(longitude, latitude),\n              color = \"red\") +\n  theme_map() +\n  annotation_north_arrow(which_north = \"grid\")\nbra"
  },
  {
    "objectID": "R_codes/Aula_10.html#mapas-interativos",
    "href": "R_codes/Aula_10.html#mapas-interativos",
    "title": "Criação de Mapas",
    "section": "",
    "text": "Através da função ggplotly() é possível criar mapas em quadros dinâmicos com interface que permite movimento, zoom e outras ferramentas de exploração.\n\nggplotly(bra)\n\n\n\n\n\nConfigurando um mapa interativo usando o pacote leaflet, com base na localização especificada (longitude e latitude de Viçosa, MG, Brasil):\n\nViçosa &lt;- leaflet() |&gt; \n  addTiles() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5)\n\nViçosa\n\n\n\n\n\nAdicionando os dados de incidência da ferrugem asiática da soja ao mapa interativo\n\nViçosa_2 &lt;- leaflet(sbr) |&gt; \n  addTiles() |&gt; \n  addCircleMarkers(radius = 2)\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\nViçosa_2"
  },
  {
    "objectID": "R_codes/Aula_10.html#gráfico-geoespacial-com-pontos-e-gráficos-de-pizza",
    "href": "R_codes/Aula_10.html#gráfico-geoespacial-com-pontos-e-gráficos-de-pizza",
    "title": "Criação de Mapas",
    "section": "",
    "text": "Combinando diferentes funcionalidades de visualização geoespacial e estatística podemos criar um gráfico interativo e informativo que mostra pontos geográficos e informações sobre a predominância de algumas doenças.\n\nlibrary(ggrepel) # Para adicionar textos que não se sobreponham aos pontos\nlibrary(scatterpie) # # Para criar gráficos de torta dispersos\n\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nBra_2 &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\", color = \"black\", linewidth = 0.5) +\n  coord_sf()+\n  geom_point(data = mapa, aes(lon, lat))+ # Plota pontos geoespaciais usando coordenadas de longitude e latitude do objeto 'mapa'.\n  geom_scatterpie(aes(x=lon, y=lat, r = 0.6),\n                  alpha = 0.8, color = NA, data = mapa,\n                  cols = c (\"DFC\",\n                            \"MA\",\n                            \"FER\",\n                            \"ANTR\",\n                            \"OIDIO\"))+ # Cria os gráficos de pizza\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                  size = 2, nudge_x = 0.2, nudge_y = 0.27, color = 'gray70', family = \"Arial\")+ # Adiciona rótulos de texto aos pontos, usando a coluna 'Local' para etiquetar cada ponto\n  scale_fill_calc()+\n  theme_map()+ \n  labs(x = \"Longitude\", y = \"Laititude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(family = \"Arieal\", size = 8))\n\nBra_2"
  },
  {
    "objectID": "R_codes/Aula_3.html",
    "href": "R_codes/Aula_3.html",
    "title": "Apredendo a importar dados",
    "section": "",
    "text": "A análise de dados tem como pré-requisito básico, obviamente, a existência dos dados a serem analisados. Idependente do procedimento de coleta de dados os dados podem ser organizados em arquivos digitais de diversos formatos. Aqui você aprenderá como trazer os seus dados para o seu projeto no Rstudio.\nPacotes necessários\n\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nVocê pode usar {warning=FALSE, message=FALSE} no cabeçalho do chunk para ocultar alertas e mensagens de carregamento.\n\n\nPara importar dados no formato CSV você pode usar a função read.csv().\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\n\n\nPara importar dados de um arquivo Excel, você pode usar o pacote readxl.\n\nlibrary(readxl)\n\ndados &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"magnesio\") \n\n# Onde: 'read_excel(\"caminho/para/arquivo.xlsx\", sheet = \"nome_da_planilha\")'\n\nPara facilitar a importação nesse caso, você pode deixar seu arquivo Excel dentro do diretório do seu projeto. Fazendo isso, você consegue encontrá-lo com apenas o nome do arquivo."
  },
  {
    "objectID": "R_codes/Aula_3.html#dados-em-formato-csv",
    "href": "R_codes/Aula_3.html#dados-em-formato-csv",
    "title": "Apredendo a importar dados",
    "section": "",
    "text": "Para importar dados no formato CSV você pode usar a função read.csv().\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")"
  },
  {
    "objectID": "R_codes/Aula_3.html#arquivos-excel",
    "href": "R_codes/Aula_3.html#arquivos-excel",
    "title": "Apredendo a importar dados",
    "section": "",
    "text": "Para importar dados de um arquivo Excel, você pode usar o pacote readxl.\n\nlibrary(readxl)\n\ndados &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"magnesio\") \n\n# Onde: 'read_excel(\"caminho/para/arquivo.xlsx\", sheet = \"nome_da_planilha\")'\n\nPara facilitar a importação nesse caso, você pode deixar seu arquivo Excel dentro do diretório do seu projeto. Fazendo isso, você consegue encontrá-lo com apenas o nome do arquivo."
  },
  {
    "objectID": "R_codes/Aula_3.html#elaboração-de-gráficos",
    "href": "R_codes/Aula_3.html#elaboração-de-gráficos",
    "title": "Apredendo a importar dados",
    "section": "Elaboração de gráficos",
    "text": "Elaboração de gráficos\nEntendo o conteúdo dos nossos dados, podemos criar gráficos através do ggplot() para facilitar a vizualização\nGráficos do tipo histograma avaliando a incidência geral e por região:\n\ncr |&gt;\n  ggplot(aes(x = inc)) +\n  geom_histogram()\n\n\n\n# Podemos obsevar a frequência de incidência de maneira geral\n\n\ncr |&gt;\n  ggplot(aes(x = inc)) +\n  geom_histogram() +\n  facet_wrap(~region)\n\n\n\n# Separando para as duas regiões destacadas\n\n#Fazendo boxplot para as mesma variável\n\ncr |&gt; \n  ggplot(aes(x = inc)) +\n  geom_boxplot()\n\n\n\ncr |&gt; \n  ggplot(aes(x = inc)) +\n  geom_boxplot() +\n  facet_wrap(~region)\n\n\n\n#Duas variáveis: propriedade e incidência\ncr |&gt;\n  ggplot(aes(x = farm, inc)) +\n  geom_boxplot()\n\n\n\n\n\n#Gráficos para severidade\ncr |&gt; \n  ggplot(aes(inc, sev2))+\n  geom_point()\n\n\n\ncr |&gt; \n  ggplot(aes(x = sev2)) +\n  geom_histogram() +\n  facet_wrap(~region)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n#Medidas de tendência central para severidade\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarize(inc_med = median(sev2),\n            inc_mean = mean(sev2),\n            sd_mean = sd(sev2))\n\n# A tibble: 3 × 4\n  cultivar inc_med inc_mean sd_mean\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved    1.64     2.16    1.82\n2 Local      17.2     18.7    11.1 \n3 Mixture     5.43     6.47    4.35\n\n\n\n#Medidas de tendência central para severidade\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarize(inc_med = median(sev2),\n            inc_mean = mean(sev2),\n            sd_mean = sd(sev2))\n\n# A tibble: 3 × 4\n  cultivar inc_med inc_mean sd_mean\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved    1.64     2.16    1.82\n2 Local      17.2     18.7    11.1 \n3 Mixture     5.43     6.47    4.35\n\n\n\n#Histogramas para a severidade por região e cultivar \ncr |&gt; \n  ggplot(aes(x = sev2, fill = region)) +\n  geom_histogram() +\n  facet_wrap(~region~cultivar, ncol = 6)+\n  theme_classic(base_size = 12)+\n  scale_fill_colorblind()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n#Gráfico histograma com cores\n\n#Gráfico1\ncr |&gt; \n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram()+\n  facet_grid(region~cultivar)+\n  scale_fill_colorblind()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n#Gráfico2\ncr |&gt; \n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram(color = 'black')+\n  facet_grid(region~cultivar)+\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  theme_minimal(base_size = 12)+\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\", fill = \"Region\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n#Salvar o último gráfico\n\nggsave(\"cr.png\", bg = 'white')\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "R_codes/Aula_3.html#modificando-dados",
    "href": "R_codes/Aula_3.html#modificando-dados",
    "title": "Apredendo a importar dados",
    "section": "Modificando dados",
    "text": "Modificando dados\nA partir do conjunto de dados inicial podemos selecionar informações úteis para, juntamente com os gráficos, facilitar o entendimento dos mesmos.\nPor exemplo, para calcular medidas de tendência central (media, mediana e desvio padrão) da variável incidência podemos utilizar:\n\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarize(inc_med = median(inc),\n            inc_mean = mean(inc),\n            sd_mean = sd(inc))\n\n# A tibble: 3 × 4\n  cultivar inc_med inc_mean sd_mean\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved    15.2     16.4    5.66\n2 Local       50.9     53.4   14.3 \n3 Mixture     31.6     31.9   11.2 \n\n\nAtribuindo este código a um objeto, você cria um novo conjunto de dados com os valores expostos.\n\nCriando subconjuntos\nUtilizando as funções select() e filter() do pacote dplyr para selecionar colunas e linhas respectivamente podemos criar subconjuntos do nosso conjunto de dados.\nFiltrando as informações para a região “Oromia”:\n\ncr_oromia &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt; \n  filter( region == \"Oromia\")\n\ncr_oromia\n\n# A tibble: 165 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1   286 Oromia Mixture   7.63\n 2   287 Oromia Mixture   9.39\n 3   288 Oromia Mixture   1.30\n 4   289 Oromia Mixture   9.79\n 5   290 Oromia Local    18.5 \n 6   291 Oromia Mixture  13.2 \n 7   292 Oromia Mixture   5.60\n 8   293 Oromia Mixture   1.06\n 9   294 Oromia Local    17.6 \n10   295 Oromia Mixture  15.4 \n# ℹ 155 more rows\n\n\nFazendo a mesma coisa para a região “SNNPR”\n\ncr_pr &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt; \n  filter( region == \"SNNPR\")\n\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows\n\n\nAgora, podemos criar gráficos com os dados de cada subconjunto\nVamos ver a severidade nos cultivares da região Oromia:\n\np1 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = cultivar, y = sev2, fill = cultivar)) +\n  geom_boxplot()+\n  labs(title = \"Oromia\",\n        x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  theme_classic()\n\np1\n\n\n\n\nAgora, na região SNNPR:\n\np2 &lt;- cr_pr |&gt; \n  ggplot(aes(x = cultivar, y = sev2, fill = cultivar)) +\n  geom_boxplot()+\n  labs(title = \"SNNPR\",\n       x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  theme_classic()\n\np2"
  },
  {
    "objectID": "R_codes/Aula_3.html#combinando-gráficos",
    "href": "R_codes/Aula_3.html#combinando-gráficos",
    "title": "Apredendo a importar dados",
    "section": "Combinando gráficos",
    "text": "Combinando gráficos\nUtilizando o pacote pacthwork é possível unir os gráficos criados de maneiras diferentes.\nCombinando os dois gráficos:\n\nlibrary(patchwork)\np1 + p2 \n\n\n\n\nVocê também pode combinar gráficos com diferentes sinais, por exemplo: “gráfico1 + gráfico2”, “(gráfico1 | gráfico2)” e “(gráfico1 / gráfico2)”.\nCombinando dois gráficos, mantendo apenas uma legenda:\n\n(p1 | p2) +\n  plot_layout(guides = 'collect')\n\n\n\n\nRemovendo os títulos dos gráficos e usando letras para indicá-los:\n\n# Criar o primeiro gráfico\n p3 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = cultivar, y = sev2,\n             fill = cultivar)) +\n  geom_boxplot()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  theme_classic()\n\np3 \n\n\n\n\n\n# Cria o segundo gráfico\np4 &lt;- cr_pr |&gt; \n  ggplot(aes(x = cultivar, y = sev2,\n             fill = cultivar)) +\n  geom_boxplot()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  theme_classic()\n\np4 \n\n\n\n\n\n# Por fim, combine os dois gráficos\n(p3 | p4) +\n  plot_layout(guides = 'collect')+\n  plot_annotation(tag_levels = 'A')\n\n\n\n\nAinda é possível rotacionar os nossos gráficos, mudando as coordenadas com o coord_flip():\n\np5 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = cultivar, y = sev2, fill = cultivar)) +\n  geom_boxplot()+\n  labs(x = \"\", #removendo o nome do eixo x por questão de estética\n       y = \"Severity (%)\")+\n  theme_classic()+\n  scale_fill_canva()+\n  coord_flip()\n\np5\n\n\n\n\n\np6 &lt;- cr_pr |&gt; \n  ggplot(aes(x = cultivar, y = sev2, fill = cultivar)) +\n  geom_boxplot()+\n  labs(x = \"\",\n       y = \"Severity (%)\")+\n  theme_classic()+\n scale_fill_canva()+\n  coord_flip()\n\np6\n\n\n\n\n\n#Combinando os dois gráficos mais uma vez\n pacht &lt;- (p5 / p6) +\n  plot_layout(guides = 'collect', axis_titles = 'collect')+\n  plot_annotation(tag_levels = 'A', title = \"Coffe rust in Ethiopia\") #Colocando o título no gráfico e separando as regiões em A e B\n \n pacht\n\n\n\n\nUtilize a função ggsave() para salvar o gráfico criado:\n\nggsave(\"patch.png\", width = 10, height = 8)\n\nVocê ainda pode inserir um tipo de gráfico diferente em um outro:\n\n# Criando um gráfico histograma\np7 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = sev2, fill = cultivar)) +\n  geom_histogram()+\n  labs(title = \"Oromia\",\n        x = \"Cultivar\",\n       y = \"Severity (%)\")+\n  theme_classic()+\n  scale_fill_canva()\np7\n\n\n\n\n\n# Inserindo no gráfico boxplot\np5 + inset_element(p7, left = 0.6, bottom = 0.6, right = 1, top = 1) + plot_layout(guides = 'collect')\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLembre-se de organizar o espaço ocupado pelos seus gráficos para não acabar ocultando informações."
  },
  {
    "objectID": "R_codes/Aula_5.html",
    "href": "R_codes/Aula_5.html",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "Aqui será apresentada uma análise das notas dos alunos da turma de FIP606 em duas provas semanais, as famosas “sabatinas”, que são corriqueiramente aplicadas nas disciplinas do nosso PPG. Acompanhe…\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\nlibrary(ggthemes)\n\n\n\n\nUtilizamos a função ‘gsheet2tbl’ do pacote gsheet para importar os dados de uma planilha google disponível através do seu link de acesso. Atribuímos os valores do conjunto de dados ao dataframe denominado ‘notas’.\n\nnotas &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\nNosso conjunto de dados corresponde as notas da turma da disciplina FIP606 em duas sabatinas aplicadas. A coluna ‘prova’ identifica os demais dados, com ‘1’ para a primeira prova e ‘2’ para a segunda, a coluna ‘pontos’ trás o número de questões acertadas e a coluna ‘nota’ possui os valores referentes ao desempenho, cada linha corresponde ao desempenho de um aluno não identificado.\n\n\n\nAtravés da a função glimpsel() do pacote dplyr obtemos um um resumo compacto e informativo dos dados.\n\nglimpse(notas)\n\nRows: 44\nColumns: 3\n$ prova  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…\n\n\nPara as posteriores análise é interessante que a coluna ‘prova’ da planilha seja interpretada como um fator categórico. Modificamos utilizando as.factor().\n\nnotas$prova &lt;- as.factor(notas$prova)\n\nComprovando a alteração no conjunto com is.factor().\n\nis.factor(notas$prova)\n\n[1] TRUE\n\n\nMais uma vez utilizando o ‘glimpse’, podemos observar a coluna ‘prova’ como um fator:\n\nglimpse(notas)\n\nRows: 44\nColumns: 3\n$ prova  &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…\n\n\n\n\n\nCom o ‘summary’ teremos um apanhado geral para a variável nota, que será analisada. Valor mínimo, máximo, média, mediana etc.\n\nsummary(notas$nota)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  42.90   68.75   85.70   79.40  100.00  100.00 \n\n\nUtilizando as funções group_by() e summarize() do pacote dplyr para obter valores correspondentes às medidas de tendência central para as notas em ambas as provas aplicadas.\n\nnotas |&gt; \n  group_by(prova) |&gt; \n  summarize(n_med = median(nota),\n            n_mean = mean(nota),\n            sd_mean = sd(nota))\n\n# A tibble: 2 × 4\n  prova n_med n_mean sd_mean\n  &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 1      85.7   79.5    19.0\n2 2      84.4   79.3    19.7\n\n\nObservamos valores de média, mediana e desvio padrão bem próximos para as notas nas duas provas, o que nos permite pensar que o desempenho nas duas provas foi semelhante. Porém, os dados ainda podem ser explorados de outra forma.\n\n\n\nAtravés das diversas funções do ggplot é possível criar uma série de gráficos com o conjunto de dados importado. Com as funções geom_boxplot() e geom_jitter() criamos um gráfico boxplot e adicionamos os pontos correspondentes às notas, respectivamente. Isso nos permite obter uma visualização rapida da dispersão dos dados, áreas de concentração e variabilidade de valores, além da mediana e dos valores extremos.\n\n notas |&gt; \n  ggplot(aes(y = nota, x = prova))+\n  geom_boxplot(fill = 'gray', color = 'black')+\n  geom_jitter(width = 0.07)+\n  theme_few()+\n  labs(x = 'Provas',\n       y = 'Notas',\n       title = 'Sabatinas FIP606',\n       caption = 'Fonte: Turma 2024')\n\n\n\n\nCriando um gráfico histograma que ira nos permitir visualizar a distribuição de dados a fim de identificar padrões de frequência ou tendências.\n\nnotas |&gt; \n  ggplot(aes(x = nota))+\n  geom_histogram(aes(fill = prova), bins = 5, color = 'black')+\n  theme_few()+\n  facet_wrap(~prova, labeller = as_labeller(c('1'= 'Prova 1', '2' = 'Prova 2')))+\n  scale_y_continuous(limits = c(0, 10), n.breaks = 4.5)+\n  labs(x = 'Nota',\n       y = 'Frequência',\n      title = 'Sabatinas FIP606',\n      caption = 'Fonte: Turma 2024')+\n  theme(legend.position = 'none')+\n  geom_vline(xintercept = mean(notas$nota),\n             linetype = \"dashed\",\n             color = 'red',\n             size = 0.75)+\n  annotate(geom = \"text\",\n           label = 'Mean',\n            x = 73, y = 8, size = 3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nCom os gráficos produzidos observa-se uma leve tendência de melhora da turma na segunda prova, com maior frequência de notas acima da média da turma.\nProduzindo um gráfico com a função geom_jitter() e geom_hline() para vizualizar a distribuição dos valores em relação a média.\n\nnotas |&gt; \n  ggplot(aes(y = nota, x = prova))+\n  geom_jitter(width = 0.35, size = 2, shape = 20)+\n  theme_few()+\n  geom_hline(yintercept = mean(notas$nota),\n             linetype = \"dashed\",\n             color = 'red',\n             size = 0.75)+\n  labs(x = 'Provas',\n       y = 'Notas',\n      title = 'Sabatinas FIP606',\n      caption = 'Fonte: Turma 2024')+\n  annotate(geom = 'text',\n           x = 0.5, y = 82,\n           label = 'Mean',\n          size = 3)\n\n\n\n\nCom este gráfico foi possível observar que o número de alunos com nota acima da média da turma na segunda prova aumentou em apenas um, uma diferença numérica não tão relevante.\n\n\n\nUtilizando o ‘filter’ podemos separar os dados em dois dataframes e assim, através da estatística descritiva fomentar uma conclusão sobre o desempenho da turma nas duas provas. Primeiro filtramos a notas da primeira prova, criamos ‘n_p1’ e calculamos a porcetagem de alunos com notas acima da média da turma.\n\nn_p1 &lt;- notas |&gt; \n  filter(prova == 1, nota &gt; mean(nota)) |&gt; \n  nrow() / \nnotas |&gt; \n  filter(prova == 1) |&gt; nrow()\n\nn_p1\n\n[1] 0.5454545\n\n\nRepetindo o processo para os dados da segunda prova.\n\nn_p2 &lt;- notas |&gt; \n  filter(prova == 2, nota &gt; mean(nota)) |&gt; \n  nrow() / \nnotas |&gt;\n  filter(prova == 2) |&gt; nrow()\n\nn_p2\n\n[1] 0.5909091\n\n\nObtendo a diferença entre as duas porcetagens, temos:\n\n(n_p1 - n_p2) *-1 #multiplicar apenas se houver necssidade de corrigir um valor negativo\n\n[1] 0.04545455\n\n\nNotamos que houve um incremento de aproximadamente 4,54% de notas acima da média na segunda prova.\nConclusão: Demonstramos aqui algumas maneiras de exploração de um conjunto de dados específico para diferentes finalidades. Através das análises realizadas observamos que não houve incremento expressivo de notas acima ou abaixo da média da turma nas duas notas"
  },
  {
    "objectID": "R_codes/Aula_5.html#pacotes-necessários",
    "href": "R_codes/Aula_5.html#pacotes-necessários",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\nlibrary(ggthemes)"
  },
  {
    "objectID": "R_codes/Aula_5.html#importando-os-dados",
    "href": "R_codes/Aula_5.html#importando-os-dados",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "Utilizamos a função ‘gsheet2tbl’ do pacote gsheet para importar os dados de uma planilha google disponível através do seu link de acesso. Atribuímos os valores do conjunto de dados ao dataframe denominado ‘notas’.\n\nnotas &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\nNosso conjunto de dados corresponde as notas da turma da disciplina FIP606 em duas sabatinas aplicadas. A coluna ‘prova’ identifica os demais dados, com ‘1’ para a primeira prova e ‘2’ para a segunda, a coluna ‘pontos’ trás o número de questões acertadas e a coluna ‘nota’ possui os valores referentes ao desempenho, cada linha corresponde ao desempenho de um aluno não identificado."
  },
  {
    "objectID": "R_codes/Aula_5.html#analisando-e-modificação-da-estrutura-dos-dados-importados",
    "href": "R_codes/Aula_5.html#analisando-e-modificação-da-estrutura-dos-dados-importados",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "Através da a função glimpsel() do pacote dplyr obtemos um um resumo compacto e informativo dos dados.\n\nglimpse(notas)\n\nRows: 44\nColumns: 3\n$ prova  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…\n\n\nPara as posteriores análise é interessante que a coluna ‘prova’ da planilha seja interpretada como um fator categórico. Modificamos utilizando as.factor().\n\nnotas$prova &lt;- as.factor(notas$prova)\n\nComprovando a alteração no conjunto com is.factor().\n\nis.factor(notas$prova)\n\n[1] TRUE\n\n\nMais uma vez utilizando o ‘glimpse’, podemos observar a coluna ‘prova’ como um fator:\n\nglimpse(notas)\n\nRows: 44\nColumns: 3\n$ prova  &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…"
  },
  {
    "objectID": "R_codes/Aula_5.html#sumarizando-informações-para-uma-variável-de-interesse",
    "href": "R_codes/Aula_5.html#sumarizando-informações-para-uma-variável-de-interesse",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "Com o ‘summary’ teremos um apanhado geral para a variável nota, que será analisada. Valor mínimo, máximo, média, mediana etc.\n\nsummary(notas$nota)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  42.90   68.75   85.70   79.40  100.00  100.00 \n\n\nUtilizando as funções group_by() e summarize() do pacote dplyr para obter valores correspondentes às medidas de tendência central para as notas em ambas as provas aplicadas.\n\nnotas |&gt; \n  group_by(prova) |&gt; \n  summarize(n_med = median(nota),\n            n_mean = mean(nota),\n            sd_mean = sd(nota))\n\n# A tibble: 2 × 4\n  prova n_med n_mean sd_mean\n  &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 1      85.7   79.5    19.0\n2 2      84.4   79.3    19.7\n\n\nObservamos valores de média, mediana e desvio padrão bem próximos para as notas nas duas provas, o que nos permite pensar que o desempenho nas duas provas foi semelhante. Porém, os dados ainda podem ser explorados de outra forma."
  },
  {
    "objectID": "R_codes/Aula_5.html#produção-de-gráficos",
    "href": "R_codes/Aula_5.html#produção-de-gráficos",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "Através das diversas funções do ggplot é possível criar uma série de gráficos com o conjunto de dados importado. Com as funções geom_boxplot() e geom_jitter() criamos um gráfico boxplot e adicionamos os pontos correspondentes às notas, respectivamente. Isso nos permite obter uma visualização rapida da dispersão dos dados, áreas de concentração e variabilidade de valores, além da mediana e dos valores extremos.\n\n notas |&gt; \n  ggplot(aes(y = nota, x = prova))+\n  geom_boxplot(fill = 'gray', color = 'black')+\n  geom_jitter(width = 0.07)+\n  theme_few()+\n  labs(x = 'Provas',\n       y = 'Notas',\n       title = 'Sabatinas FIP606',\n       caption = 'Fonte: Turma 2024')\n\n\n\n\nCriando um gráfico histograma que ira nos permitir visualizar a distribuição de dados a fim de identificar padrões de frequência ou tendências.\n\nnotas |&gt; \n  ggplot(aes(x = nota))+\n  geom_histogram(aes(fill = prova), bins = 5, color = 'black')+\n  theme_few()+\n  facet_wrap(~prova, labeller = as_labeller(c('1'= 'Prova 1', '2' = 'Prova 2')))+\n  scale_y_continuous(limits = c(0, 10), n.breaks = 4.5)+\n  labs(x = 'Nota',\n       y = 'Frequência',\n      title = 'Sabatinas FIP606',\n      caption = 'Fonte: Turma 2024')+\n  theme(legend.position = 'none')+\n  geom_vline(xintercept = mean(notas$nota),\n             linetype = \"dashed\",\n             color = 'red',\n             size = 0.75)+\n  annotate(geom = \"text\",\n           label = 'Mean',\n            x = 73, y = 8, size = 3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nCom os gráficos produzidos observa-se uma leve tendência de melhora da turma na segunda prova, com maior frequência de notas acima da média da turma.\nProduzindo um gráfico com a função geom_jitter() e geom_hline() para vizualizar a distribuição dos valores em relação a média.\n\nnotas |&gt; \n  ggplot(aes(y = nota, x = prova))+\n  geom_jitter(width = 0.35, size = 2, shape = 20)+\n  theme_few()+\n  geom_hline(yintercept = mean(notas$nota),\n             linetype = \"dashed\",\n             color = 'red',\n             size = 0.75)+\n  labs(x = 'Provas',\n       y = 'Notas',\n      title = 'Sabatinas FIP606',\n      caption = 'Fonte: Turma 2024')+\n  annotate(geom = 'text',\n           x = 0.5, y = 82,\n           label = 'Mean',\n          size = 3)\n\n\n\n\nCom este gráfico foi possível observar que o número de alunos com nota acima da média da turma na segunda prova aumentou em apenas um, uma diferença numérica não tão relevante."
  },
  {
    "objectID": "R_codes/Aula_5.html#criar-subconjuntos-e-analise-percentual",
    "href": "R_codes/Aula_5.html#criar-subconjuntos-e-analise-percentual",
    "title": "Analisando o conjunto de notas da turma de FIP606",
    "section": "",
    "text": "Utilizando o ‘filter’ podemos separar os dados em dois dataframes e assim, através da estatística descritiva fomentar uma conclusão sobre o desempenho da turma nas duas provas. Primeiro filtramos a notas da primeira prova, criamos ‘n_p1’ e calculamos a porcetagem de alunos com notas acima da média da turma.\n\nn_p1 &lt;- notas |&gt; \n  filter(prova == 1, nota &gt; mean(nota)) |&gt; \n  nrow() / \nnotas |&gt; \n  filter(prova == 1) |&gt; nrow()\n\nn_p1\n\n[1] 0.5454545\n\n\nRepetindo o processo para os dados da segunda prova.\n\nn_p2 &lt;- notas |&gt; \n  filter(prova == 2, nota &gt; mean(nota)) |&gt; \n  nrow() / \nnotas |&gt;\n  filter(prova == 2) |&gt; nrow()\n\nn_p2\n\n[1] 0.5909091\n\n\nObtendo a diferença entre as duas porcetagens, temos:\n\n(n_p1 - n_p2) *-1 #multiplicar apenas se houver necssidade de corrigir um valor negativo\n\n[1] 0.04545455\n\n\nNotamos que houve um incremento de aproximadamente 4,54% de notas acima da média na segunda prova.\nConclusão: Demonstramos aqui algumas maneiras de exploração de um conjunto de dados específico para diferentes finalidades. Através das análises realizadas observamos que não houve incremento expressivo de notas acima ou abaixo da média da turma nas duas notas"
  },
  {
    "objectID": "R_codes/Aula_6.html",
    "href": "R_codes/Aula_6.html",
    "title": "Testes de Hipóteses",
    "section": "",
    "text": "Os testes de hipótese são ferramentas estatísticas fundamentais usadas para tomar decisões baseadas em dados amostrais. Eles são projetados para avaliar a validade de afirmações sobre uma população com base em evidências coletadas em uma amostra. Aqui você aprenderá a realizar estes testes no RStudio.\nImportando os dados\n\nlibrary(gsheet)\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nVizualização gráfica\n\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot(fill = \"gray\")+\n  theme_few()\n\n\n\n\n\n\nModificando os dados\n\n# Passar os dados para o formato largo.\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n \nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\n\n\n\nAs premissas para a aplicação do teste t são fundamentais para garantir a validade dos resultados\nAs premissas são: normalidade e homogeneidade de variância.\nNormalidade\n\n# Primeira resposta\nshapiro.test(mg2$control) # No teste de shapiro a H0 é de que a distribuição é normal.\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\n\n\n#Segunda resposta\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nGráficos de histograma podem nos ajudar a concluir sobre a normalidade de distribuição dos dados, veja:\n\nhist(mg2$control)\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\nExecutando qqnorm() e qqline() também temos resposta sobre a normalidade dos dados\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n\n\n\n\nHomogeneidade de variância\n\nvar.test(mg2$control, mg2$Mg2) # HO é que a variância é homogênea.\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nRealizando o teste\n\nteste1 &lt;- t.test(mg2$control, mg2$Mg2) #Pode usar 'var.equal = FALSE' quando a variância for heterogênea\n\n\n\n\nO pacote report transcreve o resultado do seu teste estatístico e pode ser utilizado da seguinte forma:\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$control and\nmg2$Mg2 (mean of x = 15.68, mean of y = 10.52) suggests that the effect is\npositive, statistically significant, and large (difference = 5.16, 95% CI\n[3.83, 6.49], t(17.35) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n\n\n\n\n\n\nTambém conhecido como teste pareado, é aplicado quando as observações em uma amostra são dependentes, como antes e depois de um tratamento aplicado em um mesmo grupo de indivíduos.\nImportando e montando um gráfico com os dados:\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\n#Vizualizar\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot(fill = \"gray\")+\n  theme_few()\n\n\n\n\nModificações\n\n# Formato largo\nescala2 &lt;- escala |&gt; \n  dplyr::select(assessment, rater, acuracia)|&gt;\n  pivot_wider(names_from = assessment, values_from = acuracia)\n\n escala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 A        0.81   0.91\n 2 B        0.72   0.91\n 3 C        0.4    0.91\n 4 D        0.82   0.96\n 5 E        0.75   0.96\n 6 F        0.45   0.9 \n 7 G        0.81   0.85\n 8 H        0.78   0.88\n 9 I        0.78   0.95\n10 J        0.5    0.94\n\n\nTestando as premissas\nNormalidade\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\n\n\nhist(escala2$Unaided)\n\n\n\n\n\nqqnorm(escala2$Unaided)\nqqline(escala2$Unaided)\n\n\n\n\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n\n\nhist(escala2$Aided1)\n\n\n\n\n\nqqnorm(escala2$Aided1)\nqqline(escala2$Aided1)\n\n\n\n\nHomogeneidade de variância\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nRealizando o teste e reportando\n\nteste2 &lt;- t.test(escala2$Unaided, escala2$Aided1,\n                 paired = TRUE,\n                 var.equal = FALSE) #Usar 'paired = TRUE' quando o teste t for pareado (média dependentes) e 'var.equal = FALSE' quando a variância for heterogêneanea\n\n\nreport(teste2)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between escala2$Unaided and\nescala2$Aided1 (mean difference = -0.23) suggests that the effect is negative,\nstatistically significant, and large (difference = -0.23, 95% CI [-0.36,\n-0.11], t(9) = -4.42, p = 0.002; Cohen's d = -1.40, 95% CI [-2.27, -0.49])\n\n\n\n\n\nO teste de Wilcoxon, também conhecido como teste de Wilcoxon de postos sinalizados, é um teste não paramétrico utilizado para comparar duas amostras relacionadas. Ele é particularmente útil quando as premissas do teste t pareado, como a normalidade das diferenças, não são atendidas.\nCom o mesmo conjunto de dados, supondo que as premissas não sejam atendidas (p &lt; 0.05), o teste pode ser realizado da seguinte forma:\n\nteste3 &lt;- wilcox.test(escala2$Unaided, escala2$Aided1, paired = TRUE)\n\nteste3\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Unaided and escala2$Aided1\nV = 0, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n#Vizualizar\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot(fill = \"gray\")+\n  geom_jitter(width = 0.1, size = 2)+\n  theme_few()\n\n\n\nanova_micelial &lt;- aov(tcm ~ especie, data = micelial)\n \nanova_micelial\n\nCall:\n   aov(formula = tcm ~ especie, data = micelial)\n\nTerms:\n                  especie Residuals\nSum of Squares  1.4695800 0.4679167\nDeg. of Freedom         4        25\n\nResidual standard error: 0.1368089\nEstimated effects may be unbalanced\n\nsummary(anova_micelial)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(anova_micelial)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova_micelial2 &lt;- lm(tcm ~ especie, data = micelial)\n\nanova_micelial2\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nCoefficients:\n(Intercept)  especieFaus  especieFcor  especieFgra  especieFmer  \n      1.572       -0.335       -0.250       -0.660       -0.145  \n\nsummary(anova_micelial2)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\nanova(anova_micelial2)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "R_codes/Aula_6.html#teste-t-para-dois-grupos-de-médias-independentes",
    "href": "R_codes/Aula_6.html#teste-t-para-dois-grupos-de-médias-independentes",
    "title": "Testes de Hipóteses",
    "section": "",
    "text": "Modificando os dados\n\n# Passar os dados para o formato largo.\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat, values_from = comp)\n \nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\n\n\n\nAs premissas para a aplicação do teste t são fundamentais para garantir a validade dos resultados\nAs premissas são: normalidade e homogeneidade de variância.\nNormalidade\n\n# Primeira resposta\nshapiro.test(mg2$control) # No teste de shapiro a H0 é de que a distribuição é normal.\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\n\n\n#Segunda resposta\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nGráficos de histograma podem nos ajudar a concluir sobre a normalidade de distribuição dos dados, veja:\n\nhist(mg2$control)\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\nExecutando qqnorm() e qqline() também temos resposta sobre a normalidade dos dados\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n\n\n\n\nHomogeneidade de variância\n\nvar.test(mg2$control, mg2$Mg2) # HO é que a variância é homogênea.\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nRealizando o teste\n\nteste1 &lt;- t.test(mg2$control, mg2$Mg2) #Pode usar 'var.equal = FALSE' quando a variância for heterogênea\n\n\n\n\nO pacote report transcreve o resultado do seu teste estatístico e pode ser utilizado da seguinte forma:\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$control and\nmg2$Mg2 (mean of x = 15.68, mean of y = 10.52) suggests that the effect is\npositive, statistically significant, and large (difference = 5.16, 95% CI\n[3.83, 6.49], t(17.35) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])"
  },
  {
    "objectID": "R_codes/Aula_6.html#teste-t-para-dois-grupos-de-médias-dependentes",
    "href": "R_codes/Aula_6.html#teste-t-para-dois-grupos-de-médias-dependentes",
    "title": "Testes de Hipóteses",
    "section": "",
    "text": "Também conhecido como teste pareado, é aplicado quando as observações em uma amostra são dependentes, como antes e depois de um tratamento aplicado em um mesmo grupo de indivíduos.\nImportando e montando um gráfico com os dados:\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\n#Vizualizar\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot(fill = \"gray\")+\n  theme_few()\n\n\n\n\nModificações\n\n# Formato largo\nescala2 &lt;- escala |&gt; \n  dplyr::select(assessment, rater, acuracia)|&gt;\n  pivot_wider(names_from = assessment, values_from = acuracia)\n\n escala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 A        0.81   0.91\n 2 B        0.72   0.91\n 3 C        0.4    0.91\n 4 D        0.82   0.96\n 5 E        0.75   0.96\n 6 F        0.45   0.9 \n 7 G        0.81   0.85\n 8 H        0.78   0.88\n 9 I        0.78   0.95\n10 J        0.5    0.94\n\n\nTestando as premissas\nNormalidade\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\n\n\nhist(escala2$Unaided)\n\n\n\n\n\nqqnorm(escala2$Unaided)\nqqline(escala2$Unaided)\n\n\n\n\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n\n\nhist(escala2$Aided1)\n\n\n\n\n\nqqnorm(escala2$Aided1)\nqqline(escala2$Aided1)\n\n\n\n\nHomogeneidade de variância\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nRealizando o teste e reportando\n\nteste2 &lt;- t.test(escala2$Unaided, escala2$Aided1,\n                 paired = TRUE,\n                 var.equal = FALSE) #Usar 'paired = TRUE' quando o teste t for pareado (média dependentes) e 'var.equal = FALSE' quando a variância for heterogêneanea\n\n\nreport(teste2)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between escala2$Unaided and\nescala2$Aided1 (mean difference = -0.23) suggests that the effect is negative,\nstatistically significant, and large (difference = -0.23, 95% CI [-0.36,\n-0.11], t(9) = -4.42, p = 0.002; Cohen's d = -1.40, 95% CI [-2.27, -0.49])"
  },
  {
    "objectID": "R_codes/Aula_6.html#teste-de-wilcoxon",
    "href": "R_codes/Aula_6.html#teste-de-wilcoxon",
    "title": "Testes de Hipóteses",
    "section": "",
    "text": "O teste de Wilcoxon, também conhecido como teste de Wilcoxon de postos sinalizados, é um teste não paramétrico utilizado para comparar duas amostras relacionadas. Ele é particularmente útil quando as premissas do teste t pareado, como a normalidade das diferenças, não são atendidas.\nCom o mesmo conjunto de dados, supondo que as premissas não sejam atendidas (p &lt; 0.05), o teste pode ser realizado da seguinte forma:\n\nteste3 &lt;- wilcox.test(escala2$Unaided, escala2$Aided1, paired = TRUE)\n\nteste3\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Unaided and escala2$Aided1\nV = 0, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n#Vizualizar\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot(fill = \"gray\")+\n  geom_jitter(width = 0.1, size = 2)+\n  theme_few()\n\n\n\nanova_micelial &lt;- aov(tcm ~ especie, data = micelial)\n \nanova_micelial\n\nCall:\n   aov(formula = tcm ~ especie, data = micelial)\n\nTerms:\n                  especie Residuals\nSum of Squares  1.4695800 0.4679167\nDeg. of Freedom         4        25\n\nResidual standard error: 0.1368089\nEstimated effects may be unbalanced\n\nsummary(anova_micelial)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(anova_micelial)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova_micelial2 &lt;- lm(tcm ~ especie, data = micelial)\n\nanova_micelial2\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nCoefficients:\n(Intercept)  especieFaus  especieFcor  especieFgra  especieFmer  \n      1.572       -0.335       -0.250       -0.660       -0.145  \n\nsummary(anova_micelial2)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\nanova(anova_micelial2)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "R_codes/Aula_8.1.html",
    "href": "R_codes/Aula_8.1.html",
    "title": "Regressão linear",
    "section": "",
    "text": "Em experimentos onde o fator avaliado é classificado como quantitativo seu efeito deve ser estudado por meio de uma relação funcional entre o mesmo e a variável resposta. A técnica indicada neste caso é a análise de regressão.\nTrabalharemos com um conjunto de dados onde o fator testado é quatitativo.\nPacotes necessários\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(lme4)\nlibrary(r4pde)\nlibrary(broom)\nlibrary(car)\nlibrary(patchwork)\n\nImportação e Vizualização Gráfica dos Dados\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\n estande |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.1, alpha = 0.2)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = 'black', size = 0.5)+\n  theme_few()+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nCriando um filtro para avaliar os dados correspodentes ao primeiro experimento\n\nexp1 = estande |&gt; \n  filter(exp == 1)\n\n# Vizualização gráfica:\nexp1 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  theme_few()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nAjustando o Modelo Linear através do lm():\n\nlm1 &lt;- lm(nplants ~ trat,\n          data = exp1)\n\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\nRepetindo para o segundo e terceiro experimento\n\nexp2 = estande |&gt; \n  filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  theme_few()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\nexp3 = estande |&gt; \n  filter(exp == 3)\n\nexp3 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  theme_few()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\nlm3 &lt;- lm(nplants ~ trat, data = exp3)\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\nVale lembrar que para ajustar modelos lineares simples os dados devem atender as pressuposições da ANOVA já ensinadas\n\n\n\nUtilizaremos o Critério de Informação de Akaike (AIC) para verificar a qualidade dos modelos testados\nFazendo para os dados do terceito experimento e assumindo uma distribuição gaussiana, temos:\n\nglm3 &lt;- glm(nplants ~ trat,\n            data = exp3)\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\n\n\nAIC(glm3)\n\n[1] 185.0449\n\n\nAssumindo uma distribuição de poisson, temos:\n\nglm3b &lt;- glm(nplants ~ trat,\n             family = \"poisson\" (link = \"log\"),\n             data = exp3)\n\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAIC(glm3b) \n\n[1] 183.9324\n\n\nQuanto menor o valor de AIC, melhor é o modelo\n\n\n\nGLMMs são uma extensão dos GLMs que incorporam efeitos mistos, combinando efeitos fixos e aleatórios. Eles são especialmente úteis em situações onde há correlação ou variabilidade nos dados que podem ser atribuídas a diferentes níveis hierárquicos ou grupos.\nVocê pode utilizar os GLMMs através da função glmer.\n\nglmer3 &lt;- glmer(nplants ~ trat + (trat | exp), data = estande)\n\nWarning in glmer(nplants ~ trat + (trat | exp), data = estande): calling\nglmer() with family=gaussian (identity link) as a shortcut to lmer() is\ndeprecated; please call lmer() directly\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nsummary(glmer3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\n\n\nAIC(glmer3)\n\n[1] 592.8402\n\n\nGLMMs assumindo uma distribuição de poisson\n\nglmer3b &lt;- glmer(nplants ~ trat + (trat|exp), family = poisson(link = \"log\"),\n                                                              data = estande) \nsummary(glmer3b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\n\n\nAIC(glmer3b)\n\n[1] 660.7282\n\n\n\nwm &lt;- WhiteMoldSoybean\n\nwm |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se= F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n  theme_minimal()\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nfit_all &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\n\nfit_all\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\ng_inter &lt;- fit_all |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate))+\n  theme_r4pde()+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  labs(x = \"Intercept\", y = \"frequency\")\n\ng_slop &lt;- fit_all |&gt; \n  filter(term == \".$inc\") |&gt; \n  ggplot(aes(x = estimate))+\n  theme_r4pde()+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  labs(x = \"Slopes\", y = \"Frequency\")\n\n\ng_inter + g_slop\n\n\n\ndf &lt;- fit_all |&gt;\n  filter(term == \".$inc\")\n\nmean(df$estimate)\n\n[1] -19.52932\n\n\n\nmofo2 &lt;- lmer(yld ~ inc + (inc | study), data = wm,\n              REML = F)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nsummary(mofo2)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nAnova(mofo2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(&gt;Chisq)    \ninc 141.09  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(mofo2, method = \"Wald\")\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n\n\n\n\n\nUm Modelo Linear de Segunda Ordem (também conhecido como modelo quadrático) é uma extensão do modelo linear de primeira ordem que inclui termos quadráticos para capturar relações curvilíneas entre a variável dependente e as variáveis independentes.\nEsse tipo de modelo é útil quando a relação entre as variáveis não é bem representada por uma linha reta, mas sim por uma curva parabólica.\nA seguir faremos um comparação da utilização um modelo linear de primeira e segunda ordem para o próximo conjunto de dados\nImportação e Vizualização dos Dados\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nexp2 &lt;- estande |&gt; filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  theme_few()+\n  ylim(0, 100)+\n  geom_smooth(method = \"lm\",\n              se = F,\n              formula = y~poly(x,2),\n              color = \"red\")+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nO gráfico acima contém uma comparação (modelo simples em azul e o modelo quadrático em vermelho) entre ambos os modelos. Concluiremos com base nas análises estatístics à seguir.\n\n\n\nlm2 &lt;- lm(nplants~trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n\nexp2$trat2 &lt;- exp2$trat^2\n\nlm3 &lt;-lm(nplants ~trat + trat2,\n         data = exp2)\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\n\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\nRealizando a comparação pelo AIC, temos\n\nAIC(lm2)\n\n[1] 194.9597\n\n\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nCom isso, observamos que o modelo linear se segunda ordem foi o melhor.\n\n\n\nO pacote AgroR tem funções que nos permitem comparar diferentes modelos. A conclusão é baseada no valor de R², que, quanto maior, mais preciso é o modelo (diferente do AIC).\nVeja como usá-lo para o mesmo conjunto de dados:\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat, nplants, grau = 1))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 60.9857143  3.6304377 16.798447 4.929311e-14\ntrat        -0.7006912  0.1605226 -4.365063 2.473272e-04\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df      SSq       MSQ        F      p-value\nLinear     1 3196.203 3196.2031 21.82329 0.0001899378\nDeviation  4 1054.172  263.5430  1.79944 0.1729687460\nResidual  18 2636.250  146.4583                      \n\n\n[[1]]\n\n\n\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\nObserva-se que o R² melhora conforme o aumento do grau. No entanto, não podemos aceitar o grau 3, pois o estande não aumenta a concentração de inóculo. O grau 2 é o mais adequado neste caso.\n\n\n\n\nModelos não lineares são utilizados quando a relação entre a variável dependente e as variáveis independentes não pode ser adequadamente descrita por uma função linear.\nPodemos utilizar modelos não lineares na análise estatística dos dados provenientes de um experimento que avaliou seis doses de um fungicida na inibição da germinação de conídios de vinte diferentes isolados.\nImportando, modificando e vizualizando os dados\n\nsensi &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\nsensi2 &lt;- sensi|&gt; \n  group_by(code, dose) |&gt; \n  summarise(mean_germination = mean(germination))\n\n`summarise()` has grouped output by 'code'. You can override using the\n`.groups` argument.\n\nsensi2 |&gt;  \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              formula = y ~poly(x,2),\n              color = \"blue\")\n\n\n\n\nFiltrando um isolado para ajustar um modelo não linear através do pacote drc.\n\nisolado152 &lt;- sensi2 |&gt; \n  filter(code == \"152\")\n\nlibrary(drc)\n\ndrc1 &lt;-  drm(mean_germination ~ dose, data = isolado152, \n             fct = LL.3())\n\nAIC(drc1)\n\n[1] 32.57898\n\n\n\nplot(drc1)\n\n\n\n\nSumarizando o resultado\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  5.526512   7.765348  0.7117 0.5280076    \nd:(Intercept) 45.250173   1.876343 24.1162 0.0001563 ***\ne:(Intercept)  0.444356   0.077789  5.7123 0.0106434 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.65351 (3 degrees of freedom)\n\n\nPara demonstrar qual dose inibe 50% da germinação de conídios do isolado que estamos avaliando separadamente, usamos:\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.444356   0.077789 0.196796 0.691916\n\n\nEm experimentos semelhantes o pacote ec50estimator consegue realizar os ajuste dos modelos para todos os isolados de maneira mais simples. Observe:\n\nlibrary(ec50estimator)\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = sensi2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc :: LL.3())\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n\nMontando um gráfico com as doses estimadas\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()+\n  theme_few()\n\n\n\n\nAssim fica mais fácil concluir sobre qual isolado é sensivel e qual é mais resistente!"
  },
  {
    "objectID": "R_codes/Aula_8.1.html#modelo-linear-generalizado-glm",
    "href": "R_codes/Aula_8.1.html#modelo-linear-generalizado-glm",
    "title": "Regressão linear",
    "section": "",
    "text": "Utilizaremos o Critério de Informação de Akaike (AIC) para verificar a qualidade dos modelos testados\nFazendo para os dados do terceito experimento e assumindo uma distribuição gaussiana, temos:\n\nglm3 &lt;- glm(nplants ~ trat,\n            data = exp3)\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\n\n\nAIC(glm3)\n\n[1] 185.0449\n\n\nAssumindo uma distribuição de poisson, temos:\n\nglm3b &lt;- glm(nplants ~ trat,\n             family = \"poisson\" (link = \"log\"),\n             data = exp3)\n\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nAIC(glm3b) \n\n[1] 183.9324\n\n\nQuanto menor o valor de AIC, melhor é o modelo"
  },
  {
    "objectID": "R_codes/Aula_8.1.html#modelos-lineares-generalizados-de-efeitos-mistos-glmms",
    "href": "R_codes/Aula_8.1.html#modelos-lineares-generalizados-de-efeitos-mistos-glmms",
    "title": "Regressão linear",
    "section": "",
    "text": "GLMMs são uma extensão dos GLMs que incorporam efeitos mistos, combinando efeitos fixos e aleatórios. Eles são especialmente úteis em situações onde há correlação ou variabilidade nos dados que podem ser atribuídas a diferentes níveis hierárquicos ou grupos.\nVocê pode utilizar os GLMMs através da função glmer.\n\nglmer3 &lt;- glmer(nplants ~ trat + (trat | exp), data = estande)\n\nWarning in glmer(nplants ~ trat + (trat | exp), data = estande): calling\nglmer() with family=gaussian (identity link) as a shortcut to lmer() is\ndeprecated; please call lmer() directly\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nsummary(glmer3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\n\n\nAIC(glmer3)\n\n[1] 592.8402\n\n\nGLMMs assumindo uma distribuição de poisson\n\nglmer3b &lt;- glmer(nplants ~ trat + (trat|exp), family = poisson(link = \"log\"),\n                                                              data = estande) \nsummary(glmer3b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\n\n\nAIC(glmer3b)\n\n[1] 660.7282\n\n\n\nwm &lt;- WhiteMoldSoybean\n\nwm |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se= F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n  theme_minimal()\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      : NULL\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nfit_all &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\n\nfit_all\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\ng_inter &lt;- fit_all |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate))+\n  theme_r4pde()+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  labs(x = \"Intercept\", y = \"frequency\")\n\ng_slop &lt;- fit_all |&gt; \n  filter(term == \".$inc\") |&gt; \n  ggplot(aes(x = estimate))+\n  theme_r4pde()+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  labs(x = \"Slopes\", y = \"Frequency\")\n\n\ng_inter + g_slop\n\n\n\ndf &lt;- fit_all |&gt;\n  filter(term == \".$inc\")\n\nmean(df$estimate)\n\n[1] -19.52932\n\n\n\nmofo2 &lt;- lmer(yld ~ inc + (inc | study), data = wm,\n              REML = F)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nsummary(mofo2)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nAnova(mofo2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(&gt;Chisq)    \ninc 141.09  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(mofo2, method = \"Wald\")\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219"
  },
  {
    "objectID": "R_codes/Aula_8.1.html#modelo-linear-quadrático-ou-de-segunda-ordem",
    "href": "R_codes/Aula_8.1.html#modelo-linear-quadrático-ou-de-segunda-ordem",
    "title": "Regressão linear",
    "section": "",
    "text": "Um Modelo Linear de Segunda Ordem (também conhecido como modelo quadrático) é uma extensão do modelo linear de primeira ordem que inclui termos quadráticos para capturar relações curvilíneas entre a variável dependente e as variáveis independentes.\nEsse tipo de modelo é útil quando a relação entre as variáveis não é bem representada por uma linha reta, mas sim por uma curva parabólica.\nA seguir faremos um comparação da utilização um modelo linear de primeira e segunda ordem para o próximo conjunto de dados\nImportação e Vizualização dos Dados\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nexp2 &lt;- estande |&gt; filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  theme_few()+\n  ylim(0, 100)+\n  geom_smooth(method = \"lm\",\n              se = F,\n              formula = y~poly(x,2),\n              color = \"red\")+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nO gráfico acima contém uma comparação (modelo simples em azul e o modelo quadrático em vermelho) entre ambos os modelos. Concluiremos com base nas análises estatístics à seguir.\n\n\n\nlm2 &lt;- lm(nplants~trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\nhist(residuals(lm2))\n\n\n\n\n\n\n\n\nexp2$trat2 &lt;- exp2$trat^2\n\nlm3 &lt;-lm(nplants ~trat + trat2,\n         data = exp2)\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\n\n\nhist(residuals(lm3))\n\n\n\n\n\n\n\nRealizando a comparação pelo AIC, temos\n\nAIC(lm2)\n\n[1] 194.9597\n\n\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nCom isso, observamos que o modelo linear se segunda ordem foi o melhor.\n\n\n\nO pacote AgroR tem funções que nos permitem comparar diferentes modelos. A conclusão é baseada no valor de R², que, quanto maior, mais preciso é o modelo (diferente do AIC).\nVeja como usá-lo para o mesmo conjunto de dados:\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat, nplants, grau = 1))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 60.9857143  3.6304377 16.798447 4.929311e-14\ntrat        -0.7006912  0.1605226 -4.365063 2.473272e-04\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df      SSq       MSQ        F      p-value\nLinear     1 3196.203 3196.2031 21.82329 0.0001899378\nDeviation  4 1054.172  263.5430  1.79944 0.1729687460\nResidual  18 2636.250  146.4583                      \n\n\n[[1]]\n\n\n\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\nObserva-se que o R² melhora conforme o aumento do grau. No entanto, não podemos aceitar o grau 3, pois o estande não aumenta a concentração de inóculo. O grau 2 é o mais adequado neste caso."
  },
  {
    "objectID": "R_codes/Aula_8.1.html#modelo-não-linear",
    "href": "R_codes/Aula_8.1.html#modelo-não-linear",
    "title": "Regressão linear",
    "section": "",
    "text": "Modelos não lineares são utilizados quando a relação entre a variável dependente e as variáveis independentes não pode ser adequadamente descrita por uma função linear.\nPodemos utilizar modelos não lineares na análise estatística dos dados provenientes de um experimento que avaliou seis doses de um fungicida na inibição da germinação de conídios de vinte diferentes isolados.\nImportando, modificando e vizualizando os dados\n\nsensi &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\nsensi2 &lt;- sensi|&gt; \n  group_by(code, dose) |&gt; \n  summarise(mean_germination = mean(germination))\n\n`summarise()` has grouped output by 'code'. You can override using the\n`.groups` argument.\n\nsensi2 |&gt;  \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              formula = y ~poly(x,2),\n              color = \"blue\")\n\n\n\n\nFiltrando um isolado para ajustar um modelo não linear através do pacote drc.\n\nisolado152 &lt;- sensi2 |&gt; \n  filter(code == \"152\")\n\nlibrary(drc)\n\ndrc1 &lt;-  drm(mean_germination ~ dose, data = isolado152, \n             fct = LL.3())\n\nAIC(drc1)\n\n[1] 32.57898\n\n\n\nplot(drc1)\n\n\n\n\nSumarizando o resultado\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  5.526512   7.765348  0.7117 0.5280076    \nd:(Intercept) 45.250173   1.876343 24.1162 0.0001563 ***\ne:(Intercept)  0.444356   0.077789  5.7123 0.0106434 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.65351 (3 degrees of freedom)\n\n\nPara demonstrar qual dose inibe 50% da germinação de conídios do isolado que estamos avaliando separadamente, usamos:\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.444356   0.077789 0.196796 0.691916\n\n\nEm experimentos semelhantes o pacote ec50estimator consegue realizar os ajuste dos modelos para todos os isolados de maneira mais simples. Observe:\n\nlibrary(ec50estimator)\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = sensi2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc :: LL.3())\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n\nMontando um gráfico com as doses estimadas\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()+\n  theme_few()\n\n\n\n\nAssim fica mais fácil concluir sobre qual isolado é sensivel e qual é mais resistente!"
  },
  {
    "objectID": "R_codes/Aula_9.html",
    "href": "R_codes/Aula_9.html",
    "title": "Análise de Correlação de Variáveis",
    "section": "",
    "text": "A correlação é expressa por um coeficiente de correlação que varia de -1 a 1. Um coeficiente de correlação próximo de 1 indica uma forte relação linear positiva, próximo de -1 indica uma forte relação linear negativa, e próximo de 0 indica pouca ou nenhuma relação linear.\nFazendo uso da estatística, podemos afirmar que correlação entre duas variáveis é sgnificativa com base em um p valor.\nVeremos diferentes maneiras de realizar uma análise de correlação de variáveis no RStudio.\nPacotes carregados\n\nlibrary(tidyverse)\nlibrary(AgroR)\nlibrary(gsheet)\nlibrary(patchwork)\nlibrary(corrplot)\nlibrary(ggthemes)\n\n\n\nImportando os dados\n\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\nModificação e Análise Visual dos Dados\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\nimg1 &lt;- imgs |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n    \n img2 &lt;- imgs |&gt; \n   ggplot(aes(Assess, ImageJ))+\n   geom_point()+\n   geom_smooth(method = \"lm\")\n \n  img3 &lt;- imgs |&gt; \n   ggplot(aes(ImageJ, LeafDoctor))+\n   geom_point()+\n   geom_smooth(method = \"lm\")\n\n img1 + img2 + img3\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nPor análise visual, as três variáveis avaliadas apresentam fortes correlações positivas.\nRealizando a análise estatística de correlação com funções do pacote AgroR:\n\nimgs2 &lt;- imgs |&gt; \n  dplyr::select(3:5)\n\n  corgraph(imgs2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n  cor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\n  cor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\n\nVemos que o indicativo visual se confirmou.\nRefazendo a mesma análise com um outro pacote, o corrplot, é possível criar uma série de variações com o mesmo resultado. Veja:\n\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"lower\")\n\n\n\n\n\ncor_img2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"square\", type = \"lower\")\n\n\n\n\n\ncor_img &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = 'number', type = 'upper', diag = FALSE)\n\n\n\n\n\n\n\nImportando, modificando e realizando as análises\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\nReportando teste através de texto\n\ncor.test(campo2$PROD, campo2$DFC)\n\n\n    Pearson's product-moment correlation\n\ndata:  campo2$PROD and campo2$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n\n\nVizualização gráfica do novo conjunto\n\ncampo |&gt; \n  ggplot(aes(DFC, PROD))+\n  geom_jitter()\n\n\n\n\nMais uma vez o gráfico construido acompanha os resultados obtidos com a análise estatística"
  },
  {
    "objectID": "R_codes/Aula_9.html#primeiro-conjunto-de-dados",
    "href": "R_codes/Aula_9.html#primeiro-conjunto-de-dados",
    "title": "Análise de Correlação de Variáveis",
    "section": "",
    "text": "Importando os dados\n\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\nModificação e Análise Visual dos Dados\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\nimg1 &lt;- imgs |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n    \n img2 &lt;- imgs |&gt; \n   ggplot(aes(Assess, ImageJ))+\n   geom_point()+\n   geom_smooth(method = \"lm\")\n \n  img3 &lt;- imgs |&gt; \n   ggplot(aes(ImageJ, LeafDoctor))+\n   geom_point()+\n   geom_smooth(method = \"lm\")\n\n img1 + img2 + img3\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nPor análise visual, as três variáveis avaliadas apresentam fortes correlações positivas.\nRealizando a análise estatística de correlação com funções do pacote AgroR:\n\nimgs2 &lt;- imgs |&gt; \n  dplyr::select(3:5)\n\n  corgraph(imgs2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n  cor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\n  cor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\n\nVemos que o indicativo visual se confirmou.\nRefazendo a mesma análise com um outro pacote, o corrplot, é possível criar uma série de variações com o mesmo resultado. Veja:\n\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"lower\")\n\n\n\n\n\ncor_img2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"square\", type = \"lower\")\n\n\n\n\n\ncor_img &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = 'number', type = 'upper', diag = FALSE)"
  },
  {
    "objectID": "R_codes/Aula_9.html#segundo-conjunto-de-dados",
    "href": "R_codes/Aula_9.html#segundo-conjunto-de-dados",
    "title": "Análise de Correlação de Variáveis",
    "section": "",
    "text": "Importando, modificando e realizando as análises\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\nReportando teste através de texto\n\ncor.test(campo2$PROD, campo2$DFC)\n\n\n    Pearson's product-moment correlation\n\ndata:  campo2$PROD and campo2$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n\n\nVizualização gráfica do novo conjunto\n\ncampo |&gt; \n  ggplot(aes(DFC, PROD))+\n  geom_jitter()\n\n\n\n\nMais uma vez o gráfico construido acompanha os resultados obtidos com a análise estatística"
  }
]